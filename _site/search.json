[
  {
    "objectID": "About-Kevin.html",
    "href": "About-Kevin.html",
    "title": "About-Kevin",
    "section": "",
    "text": "Hi there  my name is Kevin\nI am an R/Shiny Developer with expertise in helping nonprofits collect, manage and analyze their program data. I learned data science techniques to make these jobs better.\n Pronouns: he/him\n I‚Äôm currently working on improving my data pipelines, and communicating data with Shiny Applications.\n I‚Äôm currently learning Bash and SQL\n I‚Äôm looking to collaborate on Shiny Applications.\n Ask me about data in the nonprofit sector.\n How to reach me: kevin.gilds@hey.com\n\n\nTechnical Skills"
  },
  {
    "objectID": "posts/2021-06-13-across/index.html",
    "href": "posts/2021-06-13-across/index.html",
    "title": "Across",
    "section": "",
    "text": "I made that more difficult than it had to be.\n\nI was working on analyzing twenty plus survey questions and wanted to use the forcats function collapse on all of them. I was desperately trying to combine dplyr::across with the forcats function collapse.\nThankfully, I found this Stackoverflow Post\nlibrary(dplyr)\nlibrary(forcats)\ndf %&gt;% \n    mutate(across(-pid, ~ fct_collapse(.,\n     yes = c('y', 'Y'), no = c('no', 'NO', 'n'))))\n     \nMy mistake was that I was trying to close the across function paren too soon and hence errors. Here is an example of one way I was doing it wrong.\nlibrary(dplyr)\nlibrary(forcats)\ndf %&gt;% \n    mutate(across(-pid), ~ fct_collapse(.,\n     yes = c('y', 'Y'), no = c('no', 'NO', 'n'))))\n     \n\nConclusion\nI am hoping that digging into the reason for this trouble helps me remember for next time."
  },
  {
    "objectID": "posts/2024-06-15-apologies/index.html",
    "href": "posts/2024-06-15-apologies/index.html",
    "title": "Apologies",
    "section": "",
    "text": "I never thought too much about apologies other than it is something one should do if one messes up.\nThis post provided insight for me.\nKey takeaways:\nAn apology is a chance to reconnect.\n\nan opportunity to demonstrate to the person you care about that you see them, understand them, and are concerned enough to extend yourself.\n\nI have had to receive and issue apologies this year.\nThankfully these elements of care were found in the apologies and it helps me re frame some of these experiences.\nHere is more information about apologies and how AI suggested I write this piece."
  },
  {
    "objectID": "posts/2023-12-30-topfrac-inverse/index.html",
    "href": "posts/2023-12-30-topfrac-inverse/index.html",
    "title": "Top_frac Inverse",
    "section": "",
    "text": "I had a graph in a Shiny Application that had too many values and the values were getting scrunched up. I determined to add a tab panel and display multiple views.\nI used top_frac function from the dplyr üì¶.\n\ntop_sites &lt;- reactive({\n        sites_program() %&gt;%\n        dplyr::group_by(time) %&gt;%\n        dplyr::count(site)%&gt;%\n        dplyr::top_frac(.5)\n})\n\nMy next dilemma was getting the bottom half. I used Chat-GPT and here is the transcript.\nI was able to take the example and apply to my data set. This would have taken me hours to figure our prior to this assistance.\n\nbottom_sites &lt;- reactive({\n      bottom_frac &lt;- 0.5\n      result &lt;- sites_program() %&gt;%\n        dplyr::group_by(time) %&gt;%\n        dplyr::count(site)%&gt;%\n        arrange(n) %&gt;%\n        slice(1:floor(n() * bottom_frac))\n      \n    })"
  },
  {
    "objectID": "posts/2021-12-29-submodules/index.html",
    "href": "posts/2021-12-29-submodules/index.html",
    "title": "Submodules",
    "section": "",
    "text": "Don‚Äôt forget the ns!\n\nI was trying to incorporate submodules into my Shiny Application. When I ran my application it was drawing blanks, but I don‚Äôt recall if there was an error message in the console.\nThis stack overflow post helped me figure it out. Nothing complicated‚Äì I just forgot the ns values in my submodules as well.\nHere is some additional resources on namespacing"
  },
  {
    "objectID": "posts/2024-07-07-VIM/2024-07-07-VIM.html",
    "href": "posts/2024-07-07-VIM/2024-07-07-VIM.html",
    "title": "VIM",
    "section": "",
    "text": "I purchased a new Chromebook and utilized the Linux features available on newer models. I spaced on how to work with VIM and utilized the built in tutorial. The tutorial was helpful. I understand most folks may not to work in VIM but tools like VIM are not even presented in as an option for most people. I think this relates to questions on whether we should teach git in the classroom."
  },
  {
    "objectID": "posts/2022-12-29-today-i-learned/index.html",
    "href": "posts/2022-12-29-today-i-learned/index.html",
    "title": "Today I learned",
    "section": "",
    "text": "How have I not run into the problem of filtering multiple values. I was running through some scripts but could not find the solution."
  },
  {
    "objectID": "posts/2022-12-29-today-i-learned/index.html#the-problem",
    "href": "posts/2022-12-29-today-i-learned/index.html#the-problem",
    "title": "Today I learned",
    "section": "",
    "text": "How have I not run into the problem of filtering multiple values. I was running through some scripts but could not find the solution."
  },
  {
    "objectID": "posts/2022-12-29-today-i-learned/index.html#solution",
    "href": "posts/2022-12-29-today-i-learned/index.html#solution",
    "title": "Today I learned",
    "section": "Solution:",
    "text": "Solution:\nI am pretty sure I found this on a stack overflow post\ndplyr::filter(stringr::str_detect(outcomes, 'something1|nextitem2|anotherthing3')) \nIt worked and write this to remember!"
  },
  {
    "objectID": "posts/2023-02-18-goals/index.html",
    "href": "posts/2023-02-18-goals/index.html",
    "title": "Goals",
    "section": "",
    "text": "‚ÄúWe are creative because we ship the work‚Äù\n- Seth God: The Practice page 102.\n\nI am still lacking in direction but have settled to focus in on html/css. I can do some html but it is not second nature. I am going to be working through this course. I enjoy the structure of courses in that it helps you develop muscle memory.\nI wanted to play with Docker but every time I start docker desktop it freezes my computer. I need to set some boundaries with Digital Ocean and setting up Droplets and work on Shiny Proxy."
  },
  {
    "objectID": "posts/2021-10-30-file-paths/index.html",
    "href": "posts/2021-10-30-file-paths/index.html",
    "title": "File-Paths",
    "section": "",
    "text": "Not that file paths come up in polite conversations.\n\nI had forgotten about the article but it was recently brought up on the Standard Deviations podcast.\n\n\nHilary is giving out questionable career advice in the latest episode of @NSSDeviations.To launch the segment, we‚Äôre discussing: How do you know if a company has a good data science culture?https://t.co/SuRQDaQBlj\n\n‚Äî Roger D. Peng (@rdpeng) October 29, 2021\n\n\nExcluding people I have met at an R-user group, I know two people who understand file paths."
  },
  {
    "objectID": "posts/2023-05-29-mutating-for-good/index.html",
    "href": "posts/2023-05-29-mutating-for-good/index.html",
    "title": "Mutating for Good",
    "section": "",
    "text": "I could not figure out how count the values in a column and pivot the same column in Google query function. You can do this with a Pivot Table report builder but I hate the output.\nTo resolve the issue, I made a new column based on the targeted column and was able to obtain the desired output-a Stackoverflow post gave me the idea."
  },
  {
    "objectID": "posts/2021-12-14-fun-with-readme/index.html",
    "href": "posts/2021-12-14-fun-with-readme/index.html",
    "title": "Fun with Readme & Github Actions",
    "section": "",
    "text": "I have been focused on github actions and gitlab pipelines for about two weeks, and I stumbled upon this cool post. Not only is there good content on Github Actions, but content and script for the README is awesome. In addition, numerous posts on using automated workflows and other awesome content."
  },
  {
    "objectID": "posts/2024-05-18-plumber-fun/index.html",
    "href": "posts/2024-05-18-plumber-fun/index.html",
    "title": "Plumber Fun",
    "section": "",
    "text": "I received an interesting data request and noted this would make a useful endpoint on the API.\nThe first victory was first addressing and completing the request before finding a way to automate the process.\nThe second victory was getting the end point to work after testing the function.\nHowever, when I tried to test out the endpoint again it stopped working. i was receiving a 404 error non response. This did not make sense as the other endpoints were working fine.\n\n\n\nRestart R\nRestart computer\nCompare other functions in the plumber function.\n\nI started to suspect the issue was in my filter function. I am still not clear on the reason but Chat GPT game some suggestions on my code. Straight up it started working after I took the suggestions.\n\n\nHere is the link to the chat"
  },
  {
    "objectID": "posts/2024-05-18-plumber-fun/index.html#troubleshooting-steps",
    "href": "posts/2024-05-18-plumber-fun/index.html#troubleshooting-steps",
    "title": "Plumber Fun",
    "section": "",
    "text": "Restart R\nRestart computer\nCompare other functions in the plumber function.\n\nI started to suspect the issue was in my filter function. I am still not clear on the reason but Chat GPT game some suggestions on my code. Straight up it started working after I took the suggestions.\n\n\nHere is the link to the chat"
  },
  {
    "objectID": "posts/2023-12-01-is-not-null/index.html",
    "href": "posts/2023-12-01-is-not-null/index.html",
    "title": "Is Not Null",
    "section": "",
    "text": "TIL\nIt‚Äôs true, I had an MS Access Question. I could not figure out my Is Not Null criteria was not working. This post explained it what was happening and way to resolve it.\n```{sql, eval= FALSE}\nLen([Name_Full] & ‚Äú‚Äú)=0\n\n\n\nIn my case, I wanted to exclude the null values\n\n\n\n```{sql, eval = FALSE}\nLen([Name_Full] & \"\")&gt;1\n\n\nFin"
  },
  {
    "objectID": "posts/sql_cert/sql_cert.html",
    "href": "posts/sql_cert/sql_cert.html",
    "title": "sql cert",
    "section": "",
    "text": "I have enjoyed taking the courses from this learning track.https://www.freecodecamp.org/learn/relational-database/\nWhat I have liked thus far is that the courses emphasize using the command line and using Bash. The courses have been well designed. The skills build on each other and there is a lot of repetition to reinforce concepts. The hints in the course also provide an opportunity for the student to work out the problem before the solution is provided."
  },
  {
    "objectID": "posts/2023-06-03-web-stuff/index.html",
    "href": "posts/2023-06-03-web-stuff/index.html",
    "title": "Web Stuff",
    "section": "",
    "text": "I have been trying to add a footer to my blog post with no success. Hopefully this post helps."
  },
  {
    "objectID": "posts/2021-12-11-dashboards/index.html",
    "href": "posts/2021-12-11-dashboards/index.html",
    "title": "Dashboards",
    "section": "",
    "text": "I started a project thinking I wanted to get away from a dashboard and present the information within the context of a website. Once the building process started, I realized I missed dashboard tooling. I determined scratched the idea of a traditional website and went back to the framework of a dashboard.\nAbout this time, I ran into this article about dashboards. It is a thoughtful piece on the context of dashboard troubles and when they can be useful.\nIt is wonderful when you can build a dashboard that is useful for someone even for a specific purpose. The article also serves as a reminder to keep things simple and not to get hung up on all encompassing tool."
  },
  {
    "objectID": "posts/2022-11-16-codebooks-and-more/index.html",
    "href": "posts/2022-11-16-codebooks-and-more/index.html",
    "title": "Codebooks and More",
    "section": "",
    "text": "The following is a great post for data documentation and creating a data dictionary.\nAs I was starting to work on a data dictionary for a project, I discovered the get_information_report function from the pointblank` package this morning. I love the output."
  },
  {
    "objectID": "posts/2021-12-21-maps/index.html",
    "href": "posts/2021-12-21-maps/index.html",
    "title": "Maps!",
    "section": "",
    "text": "Here is a tutorial on using the mapview package. I hope I get to use it soon."
  },
  {
    "objectID": "posts/2023-07-17-style-for-gmail/index.html",
    "href": "posts/2023-07-17-style-for-gmail/index.html",
    "title": "Style for Gmail",
    "section": "",
    "text": "I should have found it strange that my html tables that were generated for emails never had borders .\n\nNow I need an html table with borders and I struggled to figure out why my style scheme was not working.\nThis was the response from ‚ÄôChat GPT`\n\nNo, the style defined in the CSS code provided will not work in an HTML table displayed by Gmail. Gmail applies its own styling and overrides any external CSS styles that you may include in the email content.\nWhen sending HTML emails via Gmail, it‚Äôs recommended to use inline CSS styles instead of external stylesheets. Inline styles are more likely to be preserved by email clients, including Gmail.\nBy using inline styles directly on each `&lt;td&gt;` element, you ensure that the border and padding styles are applied even when viewed in Gmail or other email clients that may override external CSS.\n\n&lt;table style=\"border-collapse: collapse;\"&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 1, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 1, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 2, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 2, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 3, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 3, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 4, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 4, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 5, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 5, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 6, Cell 1&lt;/td&gt;\n    &lt;td style=\"border: 1px solid black; padding: 10px;\"&gt;Row 6, Cell 2&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\nThis is correct but seems terrible.\nThis site post pointed me to a better solution.\nBelow works without having to style each cell.\n&lt;table border=\"1px\" cellpadding=\"5px\"&gt;\n  &lt;tr&gt;\n    &lt;td&gt; Content&lt;/td&gt;\n  &lt;/tr&gt;\n  \n&lt;/table&gt;\nOn a side note; when I send the email I had my borders, when the recipient responded back the borders were gone. Maybe Outlook stripped them out."
  },
  {
    "objectID": "posts/move/move.html",
    "href": "posts/move/move.html",
    "title": "move",
    "section": "",
    "text": "I moved to Quarto and not sure how I feel about it. I know how Blogdown and Hugo can be burdensome. I just kept waiting for things to break on me. I miss my add new post Addins but I guess I should just make it myself. I will slowly port over worthwhile post to this new version of the site."
  },
  {
    "objectID": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html",
    "href": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html",
    "title": "Weather and RSS on the Command Line",
    "section": "",
    "text": "This is a fun and simplified weather display\n\nwttr.in\n\nor from a web browser"
  },
  {
    "objectID": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html#weather",
    "href": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html#weather",
    "title": "Weather and RSS on the Command Line",
    "section": "",
    "text": "This is a fun and simplified weather display\n\nwttr.in\n\nor from a web browser"
  },
  {
    "objectID": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html#rss-feeds",
    "href": "posts/2024-01-07-weather-and-rss-on-the-command-line/index.html#rss-feeds",
    "title": "Weather and RSS on the Command Line",
    "section": "RSS Feeds",
    "text": "RSS Feeds\nNewsboat presented a non intuitive way to get working. The trick was to create the url file first in the specified directory and then upload the oplm file to upload established feeds."
  },
  {
    "objectID": "posts/2022-01-05-column-names/index.html",
    "href": "posts/2022-01-05-column-names/index.html",
    "title": "Column Names",
    "section": "",
    "text": "Designed Data Management üßê\nI saw this thread today\n\n\nHave you seen @EmilyRiederer‚Äôs work on column names? https://t.co/FN05q3SzIg\n\n‚Äî Jenna Jordan (@JennaJrdn) January 5, 2022\n\n\nI recall reading this post in the past and I am sure I did not absorb the significance of it the first time. This is design applied to data management! ü§ò"
  },
  {
    "objectID": "posts/2021-12-18-abstraction/index.html",
    "href": "posts/2021-12-18-abstraction/index.html",
    "title": "Abstraction",
    "section": "",
    "text": "Introduction\nI am preparing for a presentation on shiny modules I am giving in the coming week and it got me thinking. The comparison between the use of modules and functions is on point and I want to dig into the statement some more.\n\n\nFunction based approach\n\nI was once had an analysis pipeline that I compared to a worn down car. You turn it on in the morning and not confident it was really going to start or if it did start was it going to leave you on the side of the road.\n\nMy analysis pipelines used to be long complicated R scripts but I have transitioned to using functions within script files and or Rmd files. What got me on this road was the discussion around the Drake/Targets Package.\nThe first time someone paid me to develop a Shiny Application the application was a beast with thousands of lines of code and awful to maintain.\nI tried using modules but this did not work out.\nThankfully, I was soon introduced to the Golem Package and started modularzing my applications."
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html",
    "href": "posts/maps/2018-05-09-maps.html",
    "title": "Maps",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.0.9\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(httr)\nlibrary(ggmap)\n\nGoogle's Terms of Service: https://cloud.google.com/maps-platform/terms/.\nPlease cite ggmap if you use it! See citation(\"ggmap\") for details.\n\nlibrary(here)\n\nhere() starts at /home/kgilds/kevinsblogIII"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#get-the-data",
    "href": "posts/maps/2018-05-09-maps.html#get-the-data",
    "title": "Maps",
    "section": "Get the Data",
    "text": "Get the Data\n\nurl &lt;- 'https://www.fldoe.org/core/fileparse.php/7584/urlt/1516ABS21DAYSTDistSchl.xlsx' #location of data on the internet\n\n\n#httr::GET(url, write_disk(absences &lt;- tempfile(fileext = \".xls\"))) #obtain the spreadsheet file from the internet"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#read-the-data",
    "href": "posts/maps/2018-05-09-maps.html#read-the-data",
    "title": "Maps",
    "section": "Read the data",
    "text": "Read the data\n\nabsences_2 &lt;- readxl::read_excel(\nhere(\"posts\", \"maps\", \"absences.xlsx\"),\n     skip =2) #read the spreadsheet file and skip the first two rows\n\n\n\n\n\nabsences_2 &lt;- janitor::clean_names(absences_2) #Change column names with the Janitor.\n\n\nabsences_2 &lt;- dplyr::rename(absences_2, \"absent_21_plus\" = \"absent_21_days_or_over\") #Change name again to shorten\n\nabsences_2 &lt;- dplyr::select(absences_2, 2, 4:5) #select columsn of interest"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#clean-and-convert-the-data",
    "href": "posts/maps/2018-05-09-maps.html#clean-and-convert-the-data",
    "title": "Maps",
    "section": "Clean and Convert the data",
    "text": "Clean and Convert the data\n\n#absences_2$enrollments &lt;- as.numeric(absences_2$enrollments) #Change data to numeric format\nabsences_2$absent_21_plus &lt;- as.numeric(absences_2$absent_21_plus) #change data to numeric format"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#make-my-own-percents",
    "href": "posts/maps/2018-05-09-maps.html#make-my-own-percents",
    "title": "Maps",
    "section": "Make my own percents",
    "text": "Make my own percents\n\n#absences_2 &lt;- dplyr::mutate(absences_2, percent = absent_21_plus / enrollments) \n\n\n#calculate percent \nabsences_2 &lt;- dplyr::mutate(absences_2, percent = percent_absent_21_or_more_days *100) #Convert from decimal"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#summary-stats-for-plotting",
    "href": "posts/maps/2018-05-09-maps.html#summary-stats-for-plotting",
    "title": "Maps",
    "section": "Summary Stats for plotting",
    "text": "Summary Stats for plotting\n\nabsent_21 &lt;- absences_2 %&gt;%\n  group_by(district_name) %&gt;%\n  summarise(mean = mean(percent, na.rm = TRUE))\n\n\n\nabsent_21$mean &lt;- round(absent_21$mean, 2)\n\nabsent_21\n\n# A tibble: 75 √ó 2\n   district_name  mean\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 ALACHUA       13.9 \n 2 BAKER         21.0 \n 3 BAY           12.7 \n 4 BRADFORD      18.6 \n 5 BREVARD        6.62\n 6 BROWARD        8.71\n 7 CALHOUN       20.9 \n 8 CHARLOTTE      7.58\n 9 CITRUS        11.0 \n10 CLAY           9.78\n# ‚Ä¶ with 65 more rows"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#maps",
    "href": "posts/maps/2018-05-09-maps.html#maps",
    "title": "Maps",
    "section": "Maps",
    "text": "Maps\n\nGet Florida Map\n\nstates &lt;- map_data(\"state\")\nfl_df &lt;- subset(states, region == \"florida\")\n\nThis chunks sets up how to overlay county boundaries over the Florida map.\n\ncounties &lt;- map_data(\"county\")\nfl_county &lt;- subset(counties, region == \"florida\")\n\nThis will us a map of Florida\n\nfl_base &lt;- ggplot(data = fl_df, mapping = aes(x = long, y = lat, group = group)) + \n  coord_fixed(1.3) + \n  geom_polygon(color = \"black\", fill = \"gray\")\nfl_base + theme_nothing()\n\n\n\n\n\n\n\n\n\nfl_base + theme_nothing() + \n  geom_polygon(data = fl_county, fill = NA, color = \"white\") +\n  geom_polygon(color = \"black\", fill = NA)  # get the state border back on top"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#back-to-the-educational-set",
    "href": "posts/maps/2018-05-09-maps.html#back-to-the-educational-set",
    "title": "Maps",
    "section": "Back to the educational set",
    "text": "Back to the educational set\nSchool districts in Florida pretty much align with Florida Counties. However, there is nuance between the map data and the school district data.\nThis chunk renames the district_name to match the name in the map data and matches the case.\n\nabsent_21_c &lt;- absent_21 %&gt;%\n  rename(\"subregion\" = \"district_name\") #match name with map data in preperation of joining. \n\nabsent_21_c$subregion &lt;- tolower(absent_21_c$subregion) #make lowercase\n\nabsent_21_c\n\n# A tibble: 75 √ó 2\n   subregion  mean\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 alachua   13.9 \n 2 baker     21.0 \n 3 bay       12.7 \n 4 bradford  18.6 \n 5 brevard    6.62\n 6 broward    8.71\n 7 calhoun   20.9 \n 8 charlotte  7.58\n 9 citrus    11.0 \n10 clay       9.78\n# ‚Ä¶ with 65 more rows"
  },
  {
    "objectID": "posts/maps/2018-05-09-maps.html#use-the-anti-join-to-determine-issues-with-merging",
    "href": "posts/maps/2018-05-09-maps.html#use-the-anti-join-to-determine-issues-with-merging",
    "title": "Maps",
    "section": "Use the anti-join to determine issues with merging",
    "text": "Use the anti-join to determine issues with merging\n\nnon_match &lt;- anti_join(fl_county, absent_21_c, by = \"subregion\")\n\nnon_match\n\n         long      lat group order  region  subregion\n1   -80.89018 25.79456   302 12629 florida miami-dade\n2   -80.89018 25.97218   302 12630 florida miami-dade\n3   -80.69538 25.96645   302 12631 florida miami-dade\n4   -80.68965 25.94926   302 12632 florida miami-dade\n5   -80.30003 25.94926   302 12633 florida miami-dade\n6   -80.30003 25.96072   302 12634 florida miami-dade\n7   -80.13387 25.96072   302 12635 florida miami-dade\n8   -80.13961 25.90342   302 12636 florida miami-dade\n9   -80.12814 25.85186   302 12637 florida miami-dade\n10  -80.12814 25.81748   302 12638 florida miami-dade\n11  -80.12814 25.79456   302 12639 florida miami-dade\n12  -80.13387 25.78310   302 12640 florida miami-dade\n13  -80.14534 25.77737   302 12641 florida miami-dade\n14  -80.16252 25.78310   302 12642 florida miami-dade\n15  -80.16825 25.80029   302 12643 florida miami-dade\n16  -80.16825 25.82321   302 12644 florida miami-dade\n17  -80.16252 25.85759   302 12645 florida miami-dade\n18  -80.17398 25.85759   302 12646 florida miami-dade\n19  -80.18545 25.85186   302 12647 florida miami-dade\n20  -80.19691 25.83467   302 12648 florida miami-dade\n21  -80.20263 25.78883   302 12649 florida miami-dade\n22  -80.20836 25.75445   302 12650 florida miami-dade\n23  -80.21982 25.73726   302 12651 florida miami-dade\n24  -80.25420 25.72008   302 12652 florida miami-dade\n25  -80.26566 25.69716   302 12653 florida miami-dade\n26  -80.27712 25.63986   302 12654 florida miami-dade\n27  -80.30003 25.62840   302 12655 florida miami-dade\n28  -80.31149 25.61694   302 12656 florida miami-dade\n29  -80.32296 25.59975   302 12657 florida miami-dade\n30  -80.32296 25.56538   302 12658 florida miami-dade\n31  -80.32296 25.54819   302 12659 florida miami-dade\n32  -80.33441 25.52527   302 12660 florida miami-dade\n33  -80.35160 25.49662   302 12661 florida miami-dade\n34  -80.35733 25.46225   302 12662 florida miami-dade\n35  -80.34587 25.42214   302 12663 florida miami-dade\n36  -80.32868 25.39349   302 12664 florida miami-dade\n37  -80.32868 25.37057   302 12665 florida miami-dade\n38  -80.33441 25.35338   302 12666 florida miami-dade\n39  -80.38598 25.33046   302 12667 florida miami-dade\n40  -80.39171 25.30182   302 12668 florida miami-dade\n41  -80.40317 25.29036   302 12669 florida miami-dade\n42  -80.42609 25.27317   302 12670 florida miami-dade\n43  -80.43755 25.23879   302 12671 florida miami-dade\n44  -80.44328 25.22160   302 12672 florida miami-dade\n45  -80.47192 25.23306   302 12673 florida miami-dade\n46  -80.48911 25.22733   302 12674 florida miami-dade\n47  -80.50057 25.20441   302 12675 florida miami-dade\n48  -80.51776 25.20441   302 12676 florida miami-dade\n49  -80.55787 25.23306   302 12677 florida miami-dade\n50  -80.58651 25.23879   302 12678 florida miami-dade\n51  -80.59798 25.23306   302 12679 florida miami-dade\n52  -80.59225 25.20441   302 12680 florida miami-dade\n53  -80.60944 25.19296   302 12681 florida miami-dade\n54  -80.63235 25.19296   302 12682 florida miami-dade\n55  -80.67818 25.18150   302 12683 florida miami-dade\n56  -80.71256 25.15858   302 12684 florida miami-dade\n57  -80.79278 25.15858   302 12685 florida miami-dade\n58  -80.82716 25.17576   302 12686 florida miami-dade\n59  -80.85007 25.18150   302 12687 florida miami-dade\n60  -80.89591 25.18150   302 12688 florida miami-dade\n61  -80.89018 25.79456   302 12689 florida miami-dade\n62  -81.56627 27.03215   303 12691 florida    de soto\n63  -82.05329 27.03215   303 12692 florida    de soto\n64  -82.05329 27.10090   303 12693 florida    de soto\n65  -82.21371 27.10090   303 12694 florida    de soto\n66  -82.21371 27.19831   303 12695 florida    de soto\n67  -82.15642 27.20403   303 12696 florida    de soto\n68  -82.15642 27.24414   303 12697 florida    de soto\n69  -82.05901 27.24987   303 12698 florida    de soto\n70  -82.05901 27.33582   303 12699 florida    de soto\n71  -81.56054 27.33582   303 12700 florida    de soto\n72  -81.56627 27.03215   303 12701 florida    de soto\n73  -81.57200 29.82245   345 14185 florida   st johns\n74  -81.59492 29.90267   345 14186 florida   st johns\n75  -81.58920 29.93704   345 14187 florida   st johns\n76  -81.60065 29.96569   345 14188 florida   st johns\n77  -81.66940 30.02299   345 14189 florida   st johns\n78  -81.66940 30.04591   345 14190 florida   st johns\n79  -81.66367 30.07456   345 14191 florida   st johns\n80  -81.66367 30.09174   345 14192 florida   st johns\n81  -81.66367 30.11466   345 14193 florida   st johns\n82  -81.63503 30.11466   345 14194 florida   st johns\n83  -81.62357 30.11466   345 14195 florida   st johns\n84  -81.59492 30.11466   345 14196 florida   st johns\n85  -81.55482 30.09748   345 14197 florida   st johns\n86  -81.53762 30.09174   345 14198 florida   st johns\n87  -81.53189 30.08601   345 14199 florida   st johns\n88  -81.43449 30.08601   345 14200 florida   st johns\n89  -81.42876 30.24644   345 14201 florida   st johns\n90  -81.36574 30.24644   345 14202 florida   st johns\n91  -81.35427 30.18915   345 14203 florida   st johns\n92  -81.33136 30.09748   345 14204 florida   st johns\n93  -81.29125 29.96569   345 14205 florida   st johns\n94  -81.27979 29.91986   345 14206 florida   st johns\n95  -81.29125 29.87975   345 14207 florida   st johns\n96  -81.26833 29.86256   345 14208 florida   st johns\n97  -81.25114 29.83391   345 14209 florida   st johns\n98  -81.25114 29.78808   345 14210 florida   st johns\n99  -81.24541 29.72505   345 14211 florida   st johns\n100 -81.23396 29.70213   345 14212 florida   st johns\n101 -81.21104 29.69067   345 14213 florida   st johns\n102 -81.19958 29.67348   345 14214 florida   st johns\n103 -81.19958 29.64484   345 14215 florida   st johns\n104 -81.25114 29.65056   345 14216 florida   st johns\n105 -81.29125 29.64484   345 14217 florida   st johns\n106 -81.30844 29.65056   345 14218 florida   st johns\n107 -81.31990 29.64484   345 14219 florida   st johns\n108 -81.31417 29.62765   345 14220 florida   st johns\n109 -81.52616 29.62192   345 14221 florida   st johns\n110 -81.52616 29.75370   345 14222 florida   st johns\n111 -81.53189 29.76516   345 14223 florida   st johns\n112 -81.57200 29.82245   345 14224 florida   st johns\n113 -80.33441 27.54781   346 14226 florida   st lucie\n114 -80.32868 27.50770   346 14227 florida   st lucie\n115 -80.32868 27.46760   346 14228 florida   st lucie\n116 -80.31149 27.43322   346 14229 florida   st lucie\n117 -80.27139 27.35301   346 14230 florida   st lucie\n118 -80.24274 27.29571   346 14231 florida   st lucie\n119 -80.21409 27.25560   346 14232 florida   st lucie\n120 -80.28857 27.25560   346 14233 florida   st lucie\n121 -80.28857 27.20403   346 14234 florida   st lucie\n122 -80.67245 27.20403   346 14235 florida   st lucie\n123 -80.67245 27.55354   346 14236 florida   st lucie\n124 -80.33441 27.54781   346 14237 florida   st lucie\n\n\nNot all the names match; so a touchup of subregion names is called for.\n\nabsent_21_c$subregion &lt;- gsub(\"dade\", \"miami-dade\", fixed = TRUE, absent_21_c$subregion)\n\nabsent_21_c$subregion &lt;- gsub(\"desoto\", \"de soto\", fixed = TRUE, absent_21_c$subregion)\n\nabsent_21_c$subregion &lt;- gsub(\"st. johns\", \"st johns\", fixed = TRUE, absent_21_c$subregion)\n\nabsent_21_c$subregion &lt;- gsub(\"st. lucie\", \"st lucie\", fixed = TRUE, absent_21_c$subregion)\n\n\nJoin Forces\nPut the\n\nmap_d &lt;- inner_join(fl_county, absent_21_c, by = \"subregion\") #join map data and educational data"
  },
  {
    "objectID": "posts/2021-12-23-writing-in-community/index.html",
    "href": "posts/2021-12-23-writing-in-community/index.html",
    "title": "Writing in Community",
    "section": "",
    "text": "I signed up for this workshop. I believe this will help me develop the habit of writing everyday whether I want to or not. I participated in the Freelance workshop and found the time to write on a regular basis.\nBooks topics\n\nMetallica and the practice\nAutobiography\nNonprofit Evaluation."
  },
  {
    "objectID": "posts/2023-05-25-img/index.html",
    "href": "posts/2023-05-25-img/index.html",
    "title": "The Img Tag",
    "section": "",
    "text": "I have been working on the Responsive Web Design course from freeCodeCamp.\nI seem to always have to look up the img tag.\nPer W3 School on html tags\nThe attributes of the img element are as follows:\n\nsrc\nalt\n\n\n&lt;img id=\"logo\" src=\"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\"&gt;\n\nThis example does not have the alt attribute.\nBelow is the css to manipulate the size of the image.\n\nbody {\n  background: #f5f6f7;\n  color: #1b1b32;\n  font-family: Helvetica;\n  margin: 0;\n}\n\nheader {\n  width: 100%;\n  height: 50px;\n  background-color: #1b1b32;\n  display: flex;\n}\n\n#logo {\n  width: max(100px, 18vw);\n  background-color: #0a0a23;\n  aspect-ratio: 35 / 4;\n  padding: 0.4rem;\n}"
  },
  {
    "objectID": "posts/2024-07-13-CL-Shortcuts/2024-07-13-CL-Shortcuts.html",
    "href": "posts/2024-07-13-CL-Shortcuts/2024-07-13-CL-Shortcuts.html",
    "title": "CL Shortcuts",
    "section": "",
    "text": "I tend to forget how to naviagate back a directory in the terminal but today I learned how to navigate back and forth between directories.\ncd - will toggle you between directories. touch create a new file mv change name of directory\nI working to getting into the habit of using the command line."
  },
  {
    "objectID": "posts/2022-01-02-flextable/index.html",
    "href": "posts/2022-01-02-flextable/index.html",
    "title": "flextable",
    "section": "",
    "text": "I am preparing to complete a report using officedown due at the end of the month. I was checking out the package out today and was happy to see I could at least open the output file in a LibreOffice Writer. I was worried about tables in the document but it looks like flextable seems to produce great looking tables and seems pretty straightforward to implement."
  },
  {
    "objectID": "posts/2022-11-15-likert-scales/index.html",
    "href": "posts/2022-11-15-likert-scales/index.html",
    "title": "Likert Scales",
    "section": "",
    "text": "I have been thinking about likert scales and the best way to analyze them. I came across this online book by Dwight Barry.\nThe book reminded me of the likert package and to utilize the Mann-Whitney test. What I found interesting in his approach to visualization was that the numbers are visualized instead of the category labels. I have always plotted the category labels and making the graph too busy. Thinking out loud‚Äìit may be useful for me to plot by numbers but not my intended audience.\nOther resources I gave gather up over the past few days include the following:\nVideos: Crosstab video\nPackages:\nvtree packages\nCGPfunctions"
  },
  {
    "objectID": "posts/foreign-keys/sql-foreign-keys.html",
    "href": "posts/foreign-keys/sql-foreign-keys.html",
    "title": "foreign keys",
    "section": "",
    "text": "I have been working on a SQL certification course from Freecode Camp. The most important thing that I learned today was adding a Foreign Key to a table in Postgres.\nIt drives me batty not to use commas and appreciate the parantheses.\nALTER TABLE &lt;table_name&gt; ADD FOREIGN KEY(&lt;column_name&gt;)\nREFERENCES &lt;referenced_table_name&gt;(&lt;referenced_column_name&gt;);"
  },
  {
    "objectID": "posts/2021-09-14-learning/index.html",
    "href": "posts/2021-09-14-learning/index.html",
    "title": "Shaking up Mental Models",
    "section": "",
    "text": "‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.0.9\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\n\nOnce you see it; you can‚Äôt unsee it.ü§î\n\nOne benefit of learning a new framework is that it gives you the opportunity to compare and contrast with an established mental model.\nI have been taking a Pandas Course from Kaggle and the lesson in Pandas involved establishing new variables in order to extract information from the data frame.\n\nindices = [0, 1, 10, 100]\nvar = ['country', 'province', 'region_1', 'region_2']\ndf = reviews.loc[indices, var]\n\nThis seemed like a pain in order to select certain rows and columns, but it did open my perspective to a challenge I was having.\nI have been working on reading data from a Qualtrics survey and there are nearly 147 columns and only about 117 are needed. (Long story on templated survey tools). To parse the data frame down, I had been using indexes for selections. Using an index is okay but frustrating as you are testing because the index selection breaks when there is a change to the survey. It was also a pain to write out all those terrible column names. The python script above made me think to create a vector to reference in a select statement.\n\nIs this possible‚Äìyes it is, and now I seem to see it everywhere.\n\nBelow is a minimal example with the ‚Äòmtcars‚Äô data set.\n\nremove &lt;- mtcars %&gt;%\n  dplyr::select(drat, wt, qsec)\n\nremove &lt;- names(remove) #create a vector with the names of the columns you eventually want to exclude\n\n\nnew_mtcars &lt;- mtcars %&gt;%\n  dplyr::select(-all_of(remove))  #within the select statement us the helper 'all_of' with the - operator to deselect the vector of interest. \n\n\nnew_mtcars\n\n                     mpg cyl  disp  hp vs am gear carb\nMazda RX4           21.0   6 160.0 110  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110  0  1    4    4\nDatsun 710          22.8   4 108.0  93  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175  0  0    3    2\nValiant             18.1   6 225.0 105  1  0    3    1\nDuster 360          14.3   8 360.0 245  0  0    3    4\nMerc 240D           24.4   4 146.7  62  1  0    4    2\nMerc 230            22.8   4 140.8  95  1  0    4    2\nMerc 280            19.2   6 167.6 123  1  0    4    4\nMerc 280C           17.8   6 167.6 123  1  0    4    4\nMerc 450SE          16.4   8 275.8 180  0  0    3    3\nMerc 450SL          17.3   8 275.8 180  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205  0  0    3    4\nLincoln Continental 10.4   8 460.0 215  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230  0  0    3    4\nFiat 128            32.4   4  78.7  66  1  1    4    1\nHonda Civic         30.4   4  75.7  52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65  1  1    4    1\nToyota Corona       21.5   4 120.1  97  1  0    3    1\nDodge Challenger    15.5   8 318.0 150  0  0    3    2\nAMC Javelin         15.2   8 304.0 150  0  0    3    2\nCamaro Z28          13.3   8 350.0 245  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175  0  0    3    2\nFiat X1-9           27.3   4  79.0  66  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91  0  1    5    2\nLotus Europa        30.4   4  95.1 113  1  1    5    2\nFord Pantera L      15.8   8 351.0 264  0  1    5    4\nFerrari Dino        19.7   6 145.0 175  0  1    5    6\nMaserati Bora       15.0   8 301.0 335  0  1    5    8\nVolvo 142E          21.4   4 121.0 109  1  1    4    2\n\n\n\nConclusion\nLearning python helped me shake up my mental model and apply it to my R workflow."
  },
  {
    "objectID": "posts/2021-09-24-communication-toolbox-with-shiny/index.html",
    "href": "posts/2021-09-24-communication-toolbox-with-shiny/index.html",
    "title": "Communication Toolbox with Shiny",
    "section": "",
    "text": "The Toolboxüß∞\nLast Wednesday, I presented the User Feedback chapter from Mastering Shiny for Cohort 2 of the book club from r4ds. My goal was to emphasize that a shiny application is a communication mechanism and that functions such as:\n\nValidation\nNotifications\nProgress Bars\nModal Dialogues\n\nare tools in your toolbox to improve the communication between you and your users.\n\n\nValidation\nI depend on the validation function in shiny to communicate to my users when there is no data entry for a given grant or within a given time frame.\noutput$grant_level_tbl &lt;- DT::renderDT({\n      tbl &lt;- source_level()\n      if(source_level() %&gt;% nrow() &lt; 1) {\n        validate(\"Sorry, no data available\") ##the order of this matters\n      }\n      tbl &lt;- outcome_tbl(tbl) %&gt;%\n        janitor::adorn_ns() %&gt;%\n      DT::datatable(tbl, rownames = FALSE,\n                    extensions = \"Buttons\",\n                    options = list(\n                      dom = 'tB',\n                      buttons = c('copy', 'print', 'csv')\n                    ))\n    })\nThe source_level() is reactive data and given input there may be hundreds of data points or none. My validation line states if the reactive value has less than 1 row the following message is displayed\n\nSorry, no data available.\n\nThis communicates to the program manager that surveys have not been entered yet. Most likely this is expected, but the message communicates that there is no data here to display.\nThe alternative to a validation statement is a blank graph canvas and a ugly error message with table the output.\n\n\nConclusion\nI was thinking of the validation function in terms of a practical tool but I see the importance of it as a communication tool as well. What I enjoy most about participating in the book club, is picking up detail and the opportunity for reflection."
  },
  {
    "objectID": "posts/2021-12-30-docker/index.html",
    "href": "posts/2021-12-30-docker/index.html",
    "title": "Docker",
    "section": "",
    "text": "Docker Deep Dive was recommended to me yesterday. I start using Docker and then I stop and lose the momentum. Kind of like programming, I suspect you have to do Docker in order to learn it. I just need to do it and hopefully this book can help me sustain."
  },
  {
    "objectID": "posts/2023-07-20-more-google-colab/index.html",
    "href": "posts/2023-07-20-more-google-colab/index.html",
    "title": "More Google Colab",
    "section": "",
    "text": "This article seems helpful for utilizing R in the context of Google Colab.\nFor me It has been hard to grasp other methods."
  },
  {
    "objectID": "posts/2024-03-30-purpose-of-this-data/index.html",
    "href": "posts/2024-03-30-purpose-of-this-data/index.html",
    "title": "Purpose of this data?",
    "section": "",
    "text": "This post on Data Intake Forms is insightful and useful.\nInsights:\nThe article serves as a catalyst for critical thinking about data inquiries, offering a framework that encourages individuals to ponder their data-related queries more deeply. The subheading, ‚ÄúA little friction can go a long way,‚Äù resonates particularly, highlighting the necessity of thoughtful consideration rather than hastily formulated requests. It acknowledges the common tendency to opt for convenience over precision but emphasizes that these forms should initiate conversations rather than act as barriers.\nMoreover, the parallels drawn between data intake and debugging underscore the significance of thoroughness in both processes.\nThe article presents thought-provoking questions, such as:\n\nWhat decision or action will you take with this data?\nWhat is the real problem you are trying to solve?\nWho will see this deliverable?\nWill this deliver business value in 90 days?\n\nThese questions serve as valuable checkpoints, ensuring that data collection aligns with strategic objectives and generates actionable insights.\n\n\nThe article also pointed me towards the Git Lab Data Handbook. This handbook serves as a practical guide, offering insights into effective data management practices."
  },
  {
    "objectID": "posts/2024-03-30-purpose-of-this-data/index.html#introduction",
    "href": "posts/2024-03-30-purpose-of-this-data/index.html#introduction",
    "title": "Purpose of this data?",
    "section": "",
    "text": "This post on Data Intake Forms is insightful and useful.\nInsights:\nThe article serves as a catalyst for critical thinking about data inquiries, offering a framework that encourages individuals to ponder their data-related queries more deeply. The subheading, ‚ÄúA little friction can go a long way,‚Äù resonates particularly, highlighting the necessity of thoughtful consideration rather than hastily formulated requests. It acknowledges the common tendency to opt for convenience over precision but emphasizes that these forms should initiate conversations rather than act as barriers.\nMoreover, the parallels drawn between data intake and debugging underscore the significance of thoroughness in both processes.\nThe article presents thought-provoking questions, such as:\n\nWhat decision or action will you take with this data?\nWhat is the real problem you are trying to solve?\nWho will see this deliverable?\nWill this deliver business value in 90 days?\n\nThese questions serve as valuable checkpoints, ensuring that data collection aligns with strategic objectives and generates actionable insights.\n\n\nThe article also pointed me towards the Git Lab Data Handbook. This handbook serves as a practical guide, offering insights into effective data management practices."
  },
  {
    "objectID": "posts/2022-01-08-git-hooks/index.html",
    "href": "posts/2022-01-08-git-hooks/index.html",
    "title": "Git Hooks",
    "section": "",
    "text": "I came here for an article on a .gitlab-ci.yml example and came away with an article on githooks. I think the githook is what I need!"
  },
  {
    "objectID": "posts/2021-08-31-lessons/index.html",
    "href": "posts/2021-08-31-lessons/index.html",
    "title": "Lessons",
    "section": "",
    "text": "There were warnings!ü§ï\n\nEvery August after a big grant report is complete, I update R and my packages and that can be a pain but usually not too bad. However, last year there was the crashed laptop but that was an Ubuntu version update.\nThis year I learned the importance of the renv üì¶. I had an important Shiny Application fail because of the changes in the bs4Dash. (Yes, I recall reading the warnings but I forgot).\nHonestly, I was intimidated to try the renv package because of trying packratüì¶ in the past Thus far, it does not seem to hard to work with."
  },
  {
    "objectID": "posts/2023-05-12-i-robot/index.html",
    "href": "posts/2023-05-12-i-robot/index.html",
    "title": "i, Robot",
    "section": "",
    "text": "I just completed I, Robot by Isaac Asimov. This may have been my first science fiction book and I loved it.\nWhat I loved about the book; is that is sociology.\nSociology in essence is the interplay of how human create and are shaped by social forces.\n\n‚Ä¶‚ÄúWe still the need the man [person] who is intelligent enough to think of the proper questions to ask.\n\nThink Chat GPT is it about your question and iterating and talking to the machine."
  },
  {
    "objectID": "posts/2023-01-10-wilcoxsignedranktest/index.html",
    "href": "posts/2023-01-10-wilcoxsignedranktest/index.html",
    "title": "Wilcox-signed-rank-test",
    "section": "",
    "text": "I work with Likert survey data. This article is a good reminder to be using this test even when it feels like you are working with real numbers.\nA good question to consider is if I could make a graph like those in the post with more than 2 variables?"
  },
  {
    "objectID": "posts/2023-04-05-interactive-documents/index.html",
    "href": "posts/2023-04-05-interactive-documents/index.html",
    "title": "Interactive Documents",
    "section": "",
    "text": "I confess I jump in first and then read the documentation. However, I am convinced the learning sinks in faster this way.\n\n\nI received a request for a dashboard. Um, not in the scope of work but I want to play with the interactive components of a Quarto documents.\nI jump in and I can‚Äôt not get the Server side to recognize the data. What I did not catch at first was the concept of Execution Contexts.\n\n#| context: setup\n#| include: false\n\n# load libraries\nlibrary(dplyr)\n\n# load data\ndataset &lt;- import_data(\"data.csv\")\ndataset &lt;- sample_n(dataset, 1000)\n\nI finally got my head around this was finally starting to display data. However, I was not thrilled on the output of the valueBoxes. Again, in the Quarto document it may not be the best context for them. Maybe use a general text based report.\nOne thing to consider will be to try and learn Observable JS. I am taking a class later this month."
  },
  {
    "objectID": "posts/2023-04-05-interactive-documents/index.html#the-request",
    "href": "posts/2023-04-05-interactive-documents/index.html#the-request",
    "title": "Interactive Documents",
    "section": "",
    "text": "I received a request for a dashboard. Um, not in the scope of work but I want to play with the interactive components of a Quarto documents.\nI jump in and I can‚Äôt not get the Server side to recognize the data. What I did not catch at first was the concept of Execution Contexts.\n\n#| context: setup\n#| include: false\n\n# load libraries\nlibrary(dplyr)\n\n# load data\ndataset &lt;- import_data(\"data.csv\")\ndataset &lt;- sample_n(dataset, 1000)\n\nI finally got my head around this was finally starting to display data. However, I was not thrilled on the output of the valueBoxes. Again, in the Quarto document it may not be the best context for them. Maybe use a general text based report.\nOne thing to consider will be to try and learn Observable JS. I am taking a class later this month."
  },
  {
    "objectID": "posts/2023-05-29-branches/index.html",
    "href": "posts/2023-05-29-branches/index.html",
    "title": "Branches",
    "section": "",
    "text": "This morning, I was going to make a minor change to a Shiny Application. That minor change bricked the application. Minor stress because the change was on a branch.\nGit resources:\nhttps://git-scm.com/book/en/v2\nR workflow:\nhttps://usethis.r-lib.org/reference/pull-requests.html"
  },
  {
    "objectID": "posts/2021-12-28-shiny-proxy-fun/index.html",
    "href": "posts/2021-12-28-shiny-proxy-fun/index.html",
    "title": "Shiny Proxy Fun",
    "section": "",
    "text": "This article got me thinking about other hosting possibilities such as html files and bookdown reports."
  },
  {
    "objectID": "posts/2022-01-09-nano/index.html",
    "href": "posts/2022-01-09-nano/index.html",
    "title": "Nano",
    "section": "",
    "text": "I was testing my luck/skill with this post and curious if I messed anything up editing a bash file in Nano.\nLet try this again"
  },
  {
    "objectID": "posts/2023-11-22-pivot-wider/index.html",
    "href": "posts/2023-11-22-pivot-wider/index.html",
    "title": "Pivot Longer",
    "section": "",
    "text": "I am thankful for Google Colab and the ability to use R with it. I had a challenging dataset that required conversion from wide to long format. The difficulty arose because the transformation resulted in extra rows due to multiple columns needing to be pivoted.\nAfter experimenting with different approaches, ChatGPT suggested creating keys from the column output and filtering based on those conditions. The initial code recommendation didn‚Äôt work, so I sought clarification. Ultimately, after cleaning up a NA value and identifying extra spaces in one of the columns, the following code proved to be the solution.\n\nmutate(employee_id_key = str_trim(gsub(\"employee_id_\", \"\", employee_id_key)),\n         hours_key = str_trim(gsub(\"hours_\", \"\", hours_key))) %&gt;%\n  filter(employee_id_key == hours_key) %&gt;%\n  select(-employee_id_key, -hours_key)"
  },
  {
    "objectID": "posts/2022-11-26-lazy--automation/index.html",
    "href": "posts/2022-11-26-lazy--automation/index.html",
    "title": "Lazy & Automation",
    "section": "",
    "text": "I hate repetitive tasks and will hyper fixate on ways to automate my life. Sometimes they work out sometimes they don‚Äôt.\nI have spent my weekend working with Google Apps Scripts to automate my work life. I wrote a script to draft an email with information from a google sheet. I think I will set up an automatic case note that logs to a Google Drive folder.\nThis post shows how to convert an html document to a blob object and save in a file format."
  },
  {
    "objectID": "posts/2024-11-04-SQL-Test.html",
    "href": "posts/2024-11-04-SQL-Test.html",
    "title": "Test Your SQL",
    "section": "",
    "text": "Introduction\nSQL is on my mind and this looks like an interesting resource to test those SQL skills. I struggle with new data sets so this may be a good challenge.\nI found the resource from this post on bluesky.\n\n\nStarting my new data analyst job next week and wanted to have a refresh of SQL.\nRan through the SQL Murder Mystery (mystery.knightlab.com) and SQL Island (sql-island.informatik.uni-kl.de).\nNice confidence boost seeing how much quicker and more efficient I was compared to a few months ago[image or embed]\n\n‚Äî Tim (@talbtree.bsky.social) November 4, 2024 at 3:46 PM"
  },
  {
    "objectID": "posts/2023-01-15-r--linux/index.html",
    "href": "posts/2023-01-15-r--linux/index.html",
    "title": "R & Linux",
    "section": "",
    "text": "Let me see if I recall this post when I need to re-install."
  },
  {
    "objectID": "posts/2022-01-03-data-types/index.html",
    "href": "posts/2022-01-03-data-types/index.html",
    "title": "data-types",
    "section": "",
    "text": "Common errors emerge from mix matched data types but the error ouput rarely tell you this-if ever.\nIn the console, when you print a data frame it will give you the data type of each column displayed. This is helpful because it gives you a hint. I could not figure out a way to display a data frame with the the column types below but can display the output of the str function on the mtcars data set\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nYesterday I was working with the infer package and I was working through the examples and applying the examples to my own dataset. I could not figure out why the specify function would not work.\n\nI needed a factor variable and I had a factor variable but not the right type of factor variable.\n\nI had the data type &lt;ord&gt;and it was not working. The &lt;ord&gt; data type is an ordered factor.\nIt did not work to simply convert from an &lt;ord&gt; to a regular factor.\n\nquestions &lt;- questions %&gt;%\n  dplyr::mutate(last_year = as.factor(last_year))%&gt;%\n\nIt stayed the same &lt;ord&gt;\nHowever this worked‚Äì I converted the variable to a character type and then convert it to a regular factor!\n\nquestions &lt;- questions %&gt;%\n  dplyr::mutate(last_year = as.character.factor(last_year))%&gt;%\n  dplyr::mutate(last_year = as.factor(last_year)) %&gt;%\n\nI will have update this post with some updated data."
  },
  {
    "objectID": "posts/2023-04-28-data-dictionary/index.html",
    "href": "posts/2023-04-28-data-dictionary/index.html",
    "title": "Data Dictionary",
    "section": "",
    "text": "Here is a good article about creating data dictionaries using the pointblank package"
  },
  {
    "objectID": "posts/2024-11-03-GHA.html",
    "href": "posts/2024-11-03-GHA.html",
    "title": "Github Actions",
    "section": "",
    "text": "I spent the weekend revisiting how to build a GitHub Action to automatically pull data from Clockify. It was a challenging experience that felt like my first time coding due to a series of small, avoidable mistakes. I had to piece together information from multiple sources and use ChatGPT to get my YAML formatted correctly.\n\n\nThe announcement of this book and its chapter on GitHub Actions inspired me to start this project again. I found this project workflow especially helpful.\n\nOne useful takeaway was the idea of using a DESCRIPTION file for projects, even if they‚Äôre not packages. I used an renv workflow, but encountered challenges installing the Rcpp package on the remote machine. I wonder if the setup with a DESCRIPTION file might have prevented some of these issues.\nIf you‚Äôre writing data to your repository, you need to provide write permissions. GitHub offers a default token (GITHUB_TOKEN) for GitHub Actions, which simplifies this process. Initially, I tried using my own PAT, but thanks to ChatGPT, I learned to switch to the default GITHUB_TOKEN instead:\n\nTip: GitHub provides a default GITHUB_TOKEN for Actions that usually works for most repositories, eliminating the need for a custom PAT. Replace any custom PAT reference in the git-auto-commit-action step with ${{ secrets.GITHUB_TOKEN }}.\n\n\n\n\n\nI worked through several challenges, and hopefully, the next time I attempt this, it won‚Äôt be quite as difficult."
  },
  {
    "objectID": "posts/2024-11-03-GHA.html#learning",
    "href": "posts/2024-11-03-GHA.html#learning",
    "title": "Github Actions",
    "section": "",
    "text": "The announcement of this book and its chapter on GitHub Actions inspired me to start this project again. I found this project workflow especially helpful.\n\nOne useful takeaway was the idea of using a DESCRIPTION file for projects, even if they‚Äôre not packages. I used an renv workflow, but encountered challenges installing the Rcpp package on the remote machine. I wonder if the setup with a DESCRIPTION file might have prevented some of these issues.\nIf you‚Äôre writing data to your repository, you need to provide write permissions. GitHub offers a default token (GITHUB_TOKEN) for GitHub Actions, which simplifies this process. Initially, I tried using my own PAT, but thanks to ChatGPT, I learned to switch to the default GITHUB_TOKEN instead:\n\nTip: GitHub provides a default GITHUB_TOKEN for Actions that usually works for most repositories, eliminating the need for a custom PAT. Replace any custom PAT reference in the git-auto-commit-action step with ${{ secrets.GITHUB_TOKEN }}."
  },
  {
    "objectID": "posts/2024-11-03-GHA.html#conclusion",
    "href": "posts/2024-11-03-GHA.html#conclusion",
    "title": "Github Actions",
    "section": "",
    "text": "I worked through several challenges, and hopefully, the next time I attempt this, it won‚Äôt be quite as difficult."
  },
  {
    "objectID": "posts/2021-12-08-linux-twitter/index.html",
    "href": "posts/2021-12-08-linux-twitter/index.html",
    "title": "Linux-Twitter",
    "section": "",
    "text": "Linux shell script to reduce PDF file sizeHere is a handy and useful Linux and Unix shell script that reduce PDF file size using Ghostscript. No need to upload your PDF file to the shady third-party website.https://t.co/h1l60vHwOb\n\n‚Äî howtopam (@howtopam) December 6, 2021"
  },
  {
    "objectID": "posts/2022-11-23-app-script/index.html",
    "href": "posts/2022-11-23-app-script/index.html",
    "title": "App Script",
    "section": "",
    "text": "I have been thinking about automation in the Google Workspace. There are a lot of cool things one can do with javascript with google sheets and forms.\nThis morning, I worked through a tutorial on the submit of a form to use the data to update a form template and send an email.\nThe person who posts video to this channel is a good teacher\nhttps://www.youtube.com/@ExcelGoogleSheets"
  },
  {
    "objectID": "posts/2022-11-23-app-script/index.html#automation",
    "href": "posts/2022-11-23-app-script/index.html#automation",
    "title": "App Script",
    "section": "",
    "text": "I have been thinking about automation in the Google Workspace. There are a lot of cool things one can do with javascript with google sheets and forms.\nThis morning, I worked through a tutorial on the submit of a form to use the data to update a form template and send an email.\nThe person who posts video to this channel is a good teacher\nhttps://www.youtube.com/@ExcelGoogleSheets"
  },
  {
    "objectID": "posts/2023-02-21-email-on-edit/index.html",
    "href": "posts/2023-02-21-email-on-edit/index.html",
    "title": "Email on edit",
    "section": "",
    "text": "I have been using Apps Script at work a lot and this video is what I have been looking for."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am an R/Shiny Developer with expertise in helping nonprofits collect, manage and analyze their program data. I learned data science techniques to make these jobs better.\n Pronouns: he/him\n I‚Äôm currently working on improving my data pipelines, and communicating data with Shiny Applications.\n I‚Äôm currently learning Bash and SQL\n I‚Äôm looking to collaborate on Shiny Applications.\n Ask me about data in the nonprofit sector.\n How to reach me: kevin.gilds@hey.com\n\n\n\n   \n\n\n\n\n\n\n\nShiny Posts\nR Posts\n\n\n\n\n\nClick to Expand\n\nIntro to Python ¬†Certificate\nIntro to Machine Learning Certificate\nIntermediate Machine Learning Certificate\nFeature Engineering Certificate\nPandas Certificate\n\n\n\n\n\n\n\nmy chromebook\n\n\n\n\nClick to Expand\n\nIntroduction to Chromebook Data Science\nHow to use a Chromebook\nGoogle and the Cloud\nOrganizing Data Science Projects\nVersion Control\nData Tidying\nData Visualization\nGetting Data"
  },
  {
    "objectID": "index.html#chromebook-date-science",
    "href": "index.html#chromebook-date-science",
    "title": "About",
    "section": "",
    "text": "my chromebook\n\n\n\n\nClick to Expand\n\nIntroduction to Chromebook Data Science\nHow to use a Chromebook\nGoogle and the Cloud\nOrganizing Data Science Projects\nVersion Control\nData Tidying\nData Visualization\nGetting Data"
  },
  {
    "objectID": "posts/2023-02-20-checklists/index.html",
    "href": "posts/2023-02-20-checklists/index.html",
    "title": "Checklists",
    "section": "",
    "text": "I love checklist for the precise reason I hate them‚Äìchecklists can serve as guardrails against going too fast through a process.\nCheck this websiteout for more about the meta of checklists"
  },
  {
    "objectID": "posts/2021-11-01-issue-templates/index.html",
    "href": "posts/2021-11-01-issue-templates/index.html",
    "title": "Issue-Templates",
    "section": "",
    "text": "Can I make an issue template in Gitlab!\nYes, I really needed an issue template and recalled this tweet\n\n\nBeen revamping some SOPs :: code review checklists. Learned about GitHub Issue templates which are awesome for this. Here‚Äôs an #rstats specific one https://t.co/VN0mkmHjQ7 pic.twitter.com/FvEpgHRCPL\n\n‚Äî Travis Gerke (@travisgerke) September 29, 2021\n\n\nHowever, for this project I started using gitlab as I wanted to try the updated gitlabr package. I found this issue-templates. The directions are okay, but I found that I had to use the web ‚Äòide‚Äô to create the directory in the gitlab directory.\nAnd like I figured, issue templates have been super helpful."
  },
  {
    "objectID": "posts/2024-02-12-mermaid-diagrams/index.html",
    "href": "posts/2024-02-12-mermaid-diagrams/index.html",
    "title": "Mermaid Diagrams",
    "section": "",
    "text": "I have been charged with documenting processes and have been using Mermaid. The documentation is here and what is cool is there a Live Editor."
  },
  {
    "objectID": "posts/joins/joins.html",
    "href": "posts/joins/joins.html",
    "title": "joins",
    "section": "",
    "text": "Here is the basic form of a join.\nSELECT * FROM &lt;TABLE 1&gt; JOIN TYPE &lt;TABLE 2&gt; ON &lt;TABLE 1.KEY&gt; &lt;TABLE 2.KEY&gt;\nIf the two keys are the same, one can use the Using function.\n{eval= FALSE} SELECT * FROM &lt;table_1&gt; FULL JOIN &lt;table_2&gt; USING(&lt;column&gt;);"
  },
  {
    "objectID": "posts/2023-04-03-what-to-write/index.html",
    "href": "posts/2023-04-03-what-to-write/index.html",
    "title": "What to write",
    "section": "",
    "text": "My focus has been Google App Scripts and automating a workflow that runs through Google Drive.\nThus learning JavaScript and html."
  },
  {
    "objectID": "posts/2023-06-23-today-i-learned/index.html",
    "href": "posts/2023-06-23-today-i-learned/index.html",
    "title": "Today I learned",
    "section": "",
    "text": "I have one Google Spreadsheet that I need to copy and paste the data to keep it up to date. This hurts my soul‚ÄìI was hoping to put an end to this when our organization started used Google Drive desktop to sync files.\nThe sync works just fine but I am not able to query a spreadsheet in an xls format. The workaround is create a csv file from the xls file and complete a file import into the existing spreadsheet with the option to replace the sheet."
  },
  {
    "objectID": "posts/2022-01-01-docker-tutorial/index.html",
    "href": "posts/2022-01-01-docker-tutorial/index.html",
    "title": "Docker Tutorial",
    "section": "",
    "text": "I went through this tutorial today and concepts are starting to sink in and the power of it.\nI even had to change the Python version in the Docker file to make the Flask App work. When I received the original error‚ÄìI copied the error code and did a search. This post helped me realize the error was in fact in the code and not in the docker file."
  },
  {
    "objectID": "posts/2024-07-20-maps/2024-07-20-maps.html",
    "href": "posts/2024-07-20-maps/2024-07-20-maps.html",
    "title": "Playing with Mapboxer Pkg",
    "section": "",
    "text": "I signed up for a workshop on working with the mapboxer package and wanted to ensure I got it installed on my computer and play with it prior to the workshop.\nThis blog post is following the guide for the package\n\n#Load the library\nlibrary(mapboxer)\n\nThe guide uses a pre established data set. Lets take a peak at the data set.\n\nhead(motor_vehicle_collisions_nyc)\n\n        date time       lng      lat injured killed\n1 2020-09-24 0:00 -73.99842 40.68986       0      0\n2 2020-09-24 0:00 -73.88852 40.67298       0      0\n3 2020-09-24 0:00 -73.88636 40.63082       0      0\n4 2020-09-24 0:00 -73.97634 40.64773       1      0\n5 2020-09-24 0:00 -73.88390 40.83948       1      0\n6 2020-09-24 0:00 -73.82484 40.78214       1      0\n\n\n\nNumber of People Injured\n\n# Create a source\nmotor_vehicle_collisions_nyc %&gt;%\n  dplyr::mutate(color = ifelse(injured &gt; 0, \"red\", \"yellow\")) %&gt;%\n  as_mapbox_source(lng = \"lng\", lat = \"lat\") %&gt;%\n  # Setup a map with the default source above\n  mapboxer(\n    center = c(-73.9165, 40.7114),\n    zoom = 10\n  ) %&gt;%\n  # Add a navigation control\n  add_navigation_control() %&gt;%\n  # Add a layer styling the data of the default source\n  add_circle_layer(\n    circle_color = c(\"get\", \"color\"),\n    circle_radius = 3,\n    # Use a mustache template to add popups to the layer\n    popup = \"Number of persons injured: {{injured}}\"\n  )\n\n\n\n\n\n\n\nNumber of People Killed\n\nmapboxer(\n  style = basemaps$Carto$dark_matter,\n  center = c(-73.9165, 40.7114),\n  zoom = 9,\n  minZoom = 8\n)\n\n\n\n\n\n\nmotor_vehicle_collisions_nyc %&gt;%\n  dplyr::filter(killed &gt; 0) %&gt;%\n  as_mapbox_source() %&gt;%\n  mapboxer(\n    center = c(-73.9165, 40.7114),\n    zoom = 9\n  ) %&gt;%\n  add_circle_layer(circle_color = \"red\",\n # Use a mustache template to add popups to the layer\n    popup = \"Number of persons killed: {{killed}}\"\n  )\n\n\n\n\n\n\n\nConclusion\nThe add circle layer part of the code is different from typical R code. The concept is explained in the Experssions part of the guide.\nexpr_get_property &lt;- c(\"get\", \"&lt;data-property&gt;\")\nOverall this looks like a fantastic mapping package."
  },
  {
    "objectID": "posts/freelance/index.html",
    "href": "posts/freelance/index.html",
    "title": "Text Analysis",
    "section": "",
    "text": "title: freelance-posts author: kevin date: ‚Äò2020-06-19‚Äô\n\nHow often do you formally analyze all the comments you receive. Below I will show you some ways to process text data for additional analysis.\nBelow is a simple analysis of my post from the Freelance Workshop. The workshop consisted of viewing a video by Seth Godin, and responding to question prompts and tagging . The key was writing your response and tagging other people to receive feedback and vice-versa.\nAt the end of the workshop, participants were able to download their posts into a csv file. I thought it may be good fun to analyze the data.\nI was surprised I only had 106 posts; it felt like much more and I am not sure had the capacity to write more.\n\nLoad Required packages\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidytext)\nlibrary(forcats)\nlibrary(viridis)\nlibrary(gt)\n\nBelow is a display of the first six rows and selected columns\n\npost %&gt;%\n  dplyr::select(created_at, like_count, post) %&gt;%\n  head() %&gt;%\n  gt::gt()\n\n\n\n\n\n\n\ncreated_at\nlike_count\npost\n\n\n\n\n2020-03-30 20:56:58\n1\nFor kids: Adventures of Huckleberry Finn: Learn to see the world from many perspectives and learn empathy. For adults: Lila An Inquiry Into Morals: Provides a framework for understanding life and change. For people at work: The War of Art: This book taught me how to work.\n\n\n2020-03-31 01:21:54\n1\nThank you for the welcome @traviswilson . Good question, Finn and Lilla are about trying to understand people and society.\n\n\n2020-03-31 20:37:27\n4\nHello! My name is Kevin Gilds residing in Lakeland, Florida--between Tampa and Orlando. I am here to learn how to take the next steps. I fell into my first freelancing gig and would love to do more.\n\n\n2020-03-31 21:12:07\n2\nHi Razlan, I try to get the tough stuff done early while they are still asleep. We are fortunate that we have the flexibility to alternate care giving duties. The kids are also of the age where they are able to play together most of the time well enough. Hang in there!\n\n\n2020-03-31 23:53:03\n0\nThis is a great one; I let my former boss read and has not returned yet.... :upside_down_face:\n\n\n2020-04-01 20:31:17\n3\nI am a huge fan of this podcast and blogging platform It is from the creators of Basecamp. The podcast: https://rework.fm/ The blogging/article platform https://m.signalvnoise.com/\n\n\n\n\n\n\n\nI will use the tidytext package to break down the words in the post column and put it in a tidy format for analysis.\nLets take a peak\n\npost %&gt;%\n  tidytext::unnest_tokens(word, post)%&gt;%\n   dplyr::count(word) %&gt;% # count number of words produces n\n   dplyr::arrange(desc(n)) %&gt;%\n   dplyr::filter(n &gt;=150) %&gt;%\n    gt::gt() %&gt;%\n      tab_header(\n    title = md(\"**Kevin's Top Words**\"),\n    subtitle = md(\"*The Freelance Workshop*\")\n  )\n\n\n\n\n  \n    \n      Kevin's Top Words\n    \n    \n      The Freelance Workshop\n    \n  \n  \n    \n      word\n      n\n    \n  \n  \n    to\n415\n    the\n344\n    i\n342\n    and\n237\n    a\n209\n    you\n202\n    is\n173\n    of\n161\n    this\n150\n  \n  \n  \n\n\n\n\nNot very interesting, but we can clean this up! The tidytext package has loaded stop words to help us remove common words, and I am going to add words specific to the workshop.\n\nComplete an anti-join to remove standard stop words and add your own custom words you wish to dismiss\n\nBelow are my custom words:\n\nword &lt;- c(\"topic\",\"quote\", \"post\", \"1\", \"https\", \"hey\", \"2\", \"homeroom5\", \"5\", \"3\", \"6\", \"_kevin_\", \"_imposter_\", \"34974\", \"you‚Äôre\")\n\nworkshop_stop &lt;- data.frame(word)\n\nBelow we have a script that adds some additional data processing to extract insights from the words. I added a case_when statement to deal with similiar words and the anti-join statement to remove non insightful words\n\nword_count &lt;- post %&gt;%\n  tidytext::unnest_tokens(word, post ) %&gt;% #breakdown each word of the character vector\n  dplyr::mutate(word  = case_when( #make \n      word == \"client\" ~ \"clients\",\n      TRUE ~(word)\n    )) %&gt;%  \n  dplyr::anti_join(stop_words) %&gt;% #remove standard common words\n    dplyr::anti_join(workshop_stop) %&gt;% #remove words specifc to the workshop that are not of valle\n  dplyr::count(word) %&gt;% # count number of words produces n\n   dplyr::arrange(desc(n)) %&gt;%\n   dplyr::filter(n &gt;=16) %&gt;%\n  gt::gt () %&gt;%\n  tab_header(\n    title = md(\"**Kevin's Top Words**\"),\n    subtitle = md(\"*The Freelance Workshop*\")\n  )\n\nword_count\n\n\n\n\n  \n    \n      Kevin's Top Words\n    \n    \n      The Freelance Workshop\n    \n  \n  \n    \n      word\n      n\n    \n  \n  \n    data\n83\n    clients\n66\n    time\n29\n    evaluation\n26\n    people\n23\n    skills\n18\n    farid\n17\n    process\n16\n    story\n16\n  \n  \n  \n\n\n\n\nNow we are in position to graph the data. Below is a graph of my most frequent words with a mimimum of 16.\n\n\n\n\n\n\n\n\n\nCode for the graph is here:\nWhat were the most frequent post by category?\n\n\n\n\n\n\n\n\n\nCode for the graph is here:\nThis has been a basic introduction to text mining with R. It is possible to break down comments into their components. The most suprising word that stands out to me is time. It makes me want to re-read my post and understand the context better."
  },
  {
    "objectID": "posts/2023-05-28-spreadsheet-data-to-google-calendar/index.html",
    "href": "posts/2023-05-28-spreadsheet-data-to-google-calendar/index.html",
    "title": "Spreadsheet Data to Google Calendar",
    "section": "",
    "text": "I found this blog post to help me figure how to post dates in a spreadsheet to a Google Calendar.\nAdding times can be tricky but I found putting the time in a 24:00 clock notation with no PM or AM labels works best."
  },
  {
    "objectID": "posts/2023-01-03-this-week-i-learned/index.html",
    "href": "posts/2023-01-03-this-week-i-learned/index.html",
    "title": "This week I learned",
    "section": "",
    "text": "My friend James wrote about pancakes and really he is talking about iteration.\nHow you have to flub up the first one to make the next one better but the point you have to have the first one to flub up. He provides a nice examples.\nI also think there is something about getting into flow state or the concept of shitty first drafts.\nWhen, I work on an analysis chart, table or blog post. I flub around at first and mess up the pancake."
  },
  {
    "objectID": "posts/2023-07-04-colab/index.html",
    "href": "posts/2023-07-04-colab/index.html",
    "title": "Colab",
    "section": "",
    "text": "Here is a helpful video on reading and writing data in Google Colab with Python and Pandas from Google Drive.\nHere are directions for using R"
  },
  {
    "objectID": "posts/2024-03-02-calendar--to-do-list/index.html",
    "href": "posts/2024-03-02-calendar--to-do-list/index.html",
    "title": "Calendar & To Do List",
    "section": "",
    "text": "This is a useful blog post about matching up one‚Äôs calendar and to do list.\nI appreciated the idea of doing this activity on a schedule thereby making it a process. Another takeaway it to identify opportunities to batch tasks.\n\nPS\nI had Chat-GPT offer suggestions on my blog post. The response may have been too good. I did not feel comfortable posting as my work and it felt like stealing content idea. However, I think I may use it as a springboard. Here is the link to the output.\nhttps://chat.openai.com/share/125382ab-dd9f-4088-aa20-0ba6e4c1303b"
  },
  {
    "objectID": "posts/bash/bash.html",
    "href": "posts/bash/bash.html",
    "title": "bash",
    "section": "",
    "text": "Using a bash script with Postgres database."
  },
  {
    "objectID": "posts/bash/bash.html#make-it-executable",
    "href": "posts/bash/bash.html#make-it-executable",
    "title": "bash",
    "section": "Make it executable",
    "text": "Make it executable\nchomd +x &lt;filename&gt;\nAt the top of the file add a shebang\n#!/bin/bash\n\nRead Data from CSV File\nThe script below reads the csv file and reads\ncat courses.csv | while IFS=\",\" read MAJOR COURSE\ndo\n  echo $MAJOR\ndone\n\n\nConnect to Database\nPSQL=\"psql -X --username=freecodecamp --dbname=students --no-align --tuples-only -c\"\n\n\nDatabase Variable\nMAJOR_ID=$($PSQL \"&lt;query_here&gt;\")\nMAJOR_ID=$($PSQL \"SELECT major_id FROM majors WHERE major='$MAJOR'\")\n\n\nCode Planning\nI liked this approach of using comments as a place holder for what to do next.\ndo\n  # get major_id\n\n  # if not found\n\n  # insert major\n\n  # get new major_id\n\n  # get course_id\n\n  # if not found\n\n  # insert course\n\n  # get new course_id\n\n  # insert into majors_courses\n\ndone"
  },
  {
    "objectID": "posts/2023-01-01-streatks/index.html",
    "href": "posts/2023-01-01-streatks/index.html",
    "title": "Streaks",
    "section": "",
    "text": "The year 2022 was a tough both professionally and personally. At times, they have blurred together. I feel like I am just drifting from issue to issue without any focus or strategy behind my actions. I feel a bit hopeless and lost.\nIn late June of 2022, I had an operating system crash and had to restore systems and pick back up. I lost momentum with a writing streak I had and it feels like I have stayed in survival mode since that time.\nI have tinkered with changing strategies to learn SQL and Postgress. There is a good course here.\nTo stay afloat at my day job; I have been learning Google App Script. It has been fun to pick up on some JavaScript methods. It also great that one can run some SQL in a Google Sheet. A great follow on YouTube to learn more about Google Sheets Query Function\n\n\nTo begin again is the key and play the game you wish to play. Here is an article from the Verge. Maybe personal blogging will catch on again; I just don‚Äôt think so.\n\n\n\nI think I need to write for myself and be hopeful someone may find it useful. The more I try to make it perfect the less likely it will ship.\n\n\n\nI made some changes and stole some theme settings; still can‚Äôt get a footer working but alas.\nHopefully you hear from me soon.\nThe end."
  },
  {
    "objectID": "posts/2023-01-01-streatks/index.html#section",
    "href": "posts/2023-01-01-streatks/index.html#section",
    "title": "Streaks",
    "section": "",
    "text": "The year 2022 was a tough both professionally and personally. At times, they have blurred together. I feel like I am just drifting from issue to issue without any focus or strategy behind my actions. I feel a bit hopeless and lost.\nIn late June of 2022, I had an operating system crash and had to restore systems and pick back up. I lost momentum with a writing streak I had and it feels like I have stayed in survival mode since that time.\nI have tinkered with changing strategies to learn SQL and Postgress. There is a good course here.\nTo stay afloat at my day job; I have been learning Google App Script. It has been fun to pick up on some JavaScript methods. It also great that one can run some SQL in a Google Sheet. A great follow on YouTube to learn more about Google Sheets Query Function\n\n\nTo begin again is the key and play the game you wish to play. Here is an article from the Verge. Maybe personal blogging will catch on again; I just don‚Äôt think so.\n\n\n\nI think I need to write for myself and be hopeful someone may find it useful. The more I try to make it perfect the less likely it will ship.\n\n\n\nI made some changes and stole some theme settings; still can‚Äôt get a footer working but alas.\nHopefully you hear from me soon.\nThe end."
  },
  {
    "objectID": "posts/2021-06-16-side-benefits-of-learning-r/index.html",
    "href": "posts/2021-06-16-side-benefits-of-learning-r/index.html",
    "title": "Side Benefits of Learning R",
    "section": "",
    "text": "If you take the time to learn ggplot2 you are going to learn a lot more than plotting. Depending on your purpose for learning ggplot2, that could be great or perhaps frustrating.\n\nIn my experience learning R has opened up many other content areas for me. Granted there are many paths to learning new things but I am not sure how I get to my list below if I stayed with a learning path emphasizing spreadsheets.\n\nLinux\nGit\nWeb-development\nCSSS\nHTML"
  },
  {
    "objectID": "posts/2021-12-19-til/index.html",
    "href": "posts/2021-12-19-til/index.html",
    "title": "TIL",
    "section": "",
    "text": "I wrote some functions and scripts had to complete troubleshooting to make them work\nI am not sure why I could not recall how to filter multiple values under on variable but here we are! The slice function is also becoming one of my favorite tools.\npre_numeric &lt;- pre_summary %&gt;%\n  dplyr::filter(skim_type == \"numeric\") %&gt;%\n  dplyr::slice_tail(n = 6) %&gt;%\n  dplyr::filter(skim_variable == \"var2_avg\" |\n                  skim_variable == \"var1_avg\" |\n                  skim_variable == \"var3_avg\") \n                  \nIn this function, I have to make sure that NA values are converted to zero before I can determine success or failure. The df has to be called first and then start the new dplyr statement.\nget_var_score &lt;- function(df){\n  \n    df &lt;- dplyr::mutate(df, var_adjusted = 4 - sc1) \n    df &lt;- dplyr::mutate(df, var_avg = sc0 / var_adjusted) \n    df$var_avg &lt;- tidyr::replace_na(df$var_avg, 0)\n    df \n    dplyr::mutate(df, var_success = if_else(var_avg &gt;= 4.45, TRUE, FALSE))\n    \n    \n}\nHere I needed to actually filter navalues in this column to see troubled records.\nissue_13 &lt;- survey %&gt;%\n  dplyr::filter(is.na(initials_1))"
  },
  {
    "objectID": "posts/2022-01-07-commit-to-the-static/index.html",
    "href": "posts/2022-01-07-commit-to-the-static/index.html",
    "title": "commit to the static",
    "section": "",
    "text": "Note to self\n\nYou need commit the static folder to get plots to render in blogdown.post"
  },
  {
    "objectID": "posts/remedy/addins.html",
    "href": "posts/remedy/addins.html",
    "title": "addins",
    "section": "",
    "text": "I downloaded the remedy package today."
  },
  {
    "objectID": "posts/2023-05-29-glue/index.html",
    "href": "posts/2023-05-29-glue/index.html",
    "title": "Glue",
    "section": "",
    "text": "This is how I had to get the meta data to work on my new Post Add in.\n\n# build yaml core\n  new_post_core &lt;- c(\n    \"---\",\n    glue::glue('title: \"{title}\"'),\n    \"description: |\",\n    glue::glue('  {description}'),\n    glue::glue(\"author: {author}\"),\n    glue::glue(\"date: {date}\"),\n    glue::glue(\"categories:\"),\n    glue::glue(' -{categories}')\n\n  )"
  },
  {
    "objectID": "posts/2022-01-04-a-readme-tale/index.html",
    "href": "posts/2022-01-04-a-readme-tale/index.html",
    "title": "A README Tale",
    "section": "",
    "text": "This tweet led me in many directions.\n\n\ntoday i share some #rstats adventures that challenged me üßómost of it was probably self-inflicted from not reading documentation thoroughly üò¨rmarkdown::render(‚ÄúREADME.Rmd‚Äù, ‚Äúgithub_document‚Äù) in GitHub Actions really got me tho ü•¥https://t.co/FcqAS43i2o\n\n‚Äî Shannon Pileggi (@PipingHotData) December 13, 2021\n\n\nI loved the tweet because I wanted to follow up on the automated testing components. I am hoping to still get there, but thus far I have learned a lot on the web scraping elements of my website and see some other possibilities. It will need a weekend post to illuminate more‚Ä¶‚Ä¶‚Ä¶‚Ä¶\nHowever, check out the README for this site."
  },
  {
    "objectID": "posts/2023-06-22-unpivot/index.html",
    "href": "posts/2023-06-22-unpivot/index.html",
    "title": "UNPIVOT",
    "section": "",
    "text": "I watched this video on YouTube of a creator working with ChatGPT on writing formulas and Google App Script for Google Sheets.\nHere is a link to my conversation with ChatGPT about converting wide data to a long format.\nThe fun part was that ChatGPT just made up a Google Sheets function; however this function should exist in Google Sheets.\n\n\"Open your Google Sheets document and navigate to a new sheet or a blank area where you want to create your long-format data set.\nIn the first cell of the new sheet, enter the following formula: =UNPIVOT(SourceSheet!A1:D, 'New Header Column, New Value Column)'\"\n\n    \"Replace SourceSheet!A1:D with the range of your wide data set.\n    Replace New Header Column with the desired header name for the column that will contain the original header values.\n    Replace New Value Column with the desired header name for the column that will contain the corresponding values.\n\nThis seems like you would do this data manipulation in R and maybe Python.\nWhen I called ChatGPT out on it here was the response:\n\nHello, is UNPIVOT a google sheet function?\n\n\nApologies for the confusion caused. I apologize for the incorrect information provided earlier. The UNPIVOT function is not a built-in function in Google Sheets. I apologize for the oversight in my previous response."
  },
  {
    "objectID": "posts/2022-11-12-reprex/index.html",
    "href": "posts/2022-11-12-reprex/index.html",
    "title": "Reprex",
    "section": "",
    "text": "Introduction\nToday, I wanted to create reprex to show how I used a function to re-level factors in r.\nMy challenge was that I needed to read in some data and was getting an error when the reprex ran and I could not figure out the problem.\nThe reprex website had the documentation I needed to re-group and resolve the issue.\nI was not able to use the addin but called the function from the console and needed to use the wd=‚Äú.‚Äù argument.\n\n\nII Other Factor Stuff\nA good video on generating crosstab reports in R.\nhttps://www.infoworld.com/video/104862/how-to-create-crosstab-reports-in-r\nA couple of interesting packages to check out\nThese looks like a promising data vis package vtree and the CGPFunctions"
  },
  {
    "objectID": "posts/2022-12-16-data-types/index.html",
    "href": "posts/2022-12-16-data-types/index.html",
    "title": "Data Types",
    "section": "",
    "text": "I use the case_when function to clean up data entry issues and I was stumped for a bit when my common structure did not work.\nI am prone to messing up a case_when statements but I was getting frustrated after a few failures and non helpful error messages. I isolated the problem down and realized the pattern is that the case_when statement was not working on ordinal level variables. I changed the data type of these variables to character and was back in business.\nCheck your data types when a function or script is not working as expected."
  },
  {
    "objectID": "posts/2022-12-16-data-types/index.html#today-i-remembered",
    "href": "posts/2022-12-16-data-types/index.html#today-i-remembered",
    "title": "Data Types",
    "section": "",
    "text": "I use the case_when function to clean up data entry issues and I was stumped for a bit when my common structure did not work.\nI am prone to messing up a case_when statements but I was getting frustrated after a few failures and non helpful error messages. I isolated the problem down and realized the pattern is that the case_when statement was not working on ordinal level variables. I changed the data type of these variables to character and was back in business.\nCheck your data types when a function or script is not working as expected."
  },
  {
    "objectID": "posts/2024-11-10-Style-Shiny-App/2024-11-10-Style-Shiny-App.html",
    "href": "posts/2024-11-10-Style-Shiny-App/2024-11-10-Style-Shiny-App.html",
    "title": "Stylying a Shiny App",
    "section": "",
    "text": "I was running into a issue of formatting a shiny application. In a tab panel, the content was running into the left margin. I asked Claude A.I and it gave me 3 options.\nI chose the following and it worked like a charm.\n\ndiv(\n    style = \"margin: 20px;\",     # Or use padding: 20px;\n    # Your plots and tables here\n  )"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html",
    "href": "posts/2023-11-04-synthetic-data/index.html",
    "title": "Synthetic data",
    "section": "",
    "text": "Andrew Heiss teaches Program Evaluation and has wonderful resources for Sampling with R and Synthetic Data.\nhttps://evalsp23.classes.andrewheiss.com/example/random-numbers.html\nhttps://evalsp23.classes.andrewheiss.com/example/synthetic-data.html\nI will be playing with the examples from these sites and hopefully not copying it.\nHeiss, A. (2023-11-18) Program Evaluation . https://evalsp23.classes.andrewheiss.com/example/random-numbers.html\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.4.3     ‚úî purrr   1.0.2\n‚úî tibble  3.2.1     ‚úî dplyr   1.1.3\n‚úî tidyr   1.3.0     ‚úî stringr 1.5.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(patchwork)\nlibrary(truncnorm)"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#set-seeds",
    "href": "posts/2023-11-04-synthetic-data/index.html#set-seeds",
    "title": "Synthetic data",
    "section": "Set Seeds",
    "text": "Set Seeds\nI asked for 5 random numbers\n\nset.seed(110772)\n\nsample(1:10, 3)\n\n[1] 7 4 3\n\nset.seed(110772)\n\nsample(1:10, 3)\n\n[1] 7 4 3\n\n\n\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 10  6  5\n\nsample(1:10, 3) \n\n[1] 9 5 6\n\n\n\nset.seed(1234)\n\nsample(1:10, 3)\n\n[1] 10  6  5\n\nsample(1:10, 3)\n\n[1] 9 5 6"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#uniform-distributions",
    "href": "posts/2023-11-04-synthetic-data/index.html#uniform-distributions",
    "title": "Synthetic data",
    "section": "Uniform Distributions",
    "text": "Uniform Distributions\nEvery number is equally likely to be drawn\nTwo base r functions: sample runif\n\npossible_answers &lt;- c(1:6)\n\n\nsample(possible_answers, size = 1)\n\n[1] 4\n\nsample(possible_answers, size = 3)\n\n[1] 2 6 5\n\n\n\nsample(possible_answers, size = 10, replace = TRUE)\n\n [1] 6 4 6 6 6 4 4 5 4 3\n\n\n\nsample(possible_answers, size = 8)\n\n\nset.seed(1234)\ndie &lt;- tibble(value = sample(possible_answers,\n                             size = 1000,\n                             replace = TRUE))\ndie %&gt;%\n  count(value)\n\n# A tibble: 6 √ó 2\n  value     n\n  &lt;int&gt; &lt;int&gt;\n1     1   161\n2     2   153\n3     3   188\n4     4   149\n5     5   157\n6     6   192\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"1,000 rolls of a single die\")\n\n\n\n\n\n\n\n\nThe reason they are not the same is because of randomness.\nThe next example increases the sample size‚Äìcentral limit theorem.\n\nset.seed(1234)\ndie &lt;- tibble(value = sample(possible_answers,\n                             size = 100000,\n                             replace = TRUE))\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"100,000 rolls of a single die\")\n\n\n\n\n\n\n\n\nThe runif function which means random uniform functions\n\nrunif(5)\n\n[1] 0.09862408 0.96294192 0.88655414 0.05623182 0.44451637\n\n## [1] 0.09862 0.96294 0.88655 0.05623 0.44452\n\nIndicate a range\n\nrunif(5, min = 35, max = 56)\n\n[1] 46.82529 42.88636 37.74566 53.22182 46.13240\n\n## [1] 46.83 42.89 37.75 53.22 46.13\n\nWhat if I need whole numbers.\n\n# Generate 5 people between the ages of 18 and 35\nround(runif(5, min = 18, max = 35), 0)\n\n[1] 21 28 33 34 31\n\n## [1] 21 28 33 34 31\n\n\nset.seed(1234)\nlots_of_numbers &lt;- tibble(x = runif(5000, min = 18, max = 35))\n\nggplot(lots_of_numbers, aes(x = x)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 18)"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#normal-distribution",
    "href": "posts/2023-11-04-synthetic-data/index.html#normal-distribution",
    "title": "Synthetic data",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nContrast with a uniform distribution. Most data clusters around a center of graviity.\n\nEach distribution is defined by different things called parameters or values that determine the shape of the probabilities and location of clusters.\n\nA normal distribution has two parameters.\n\nmean\nstandard deviation\n\nrnorm takes there arguments:\n\nThe number of numbers one wants to generate\nthe mean default is 0\nstandard deviation default is 1\n\n\nrnorm(5)\n\n[1] -1.3662376  0.5392093 -1.3219320 -0.2812887 -2.1049469\n\n## [1] -1.3662  0.5392 -1.3219 -0.2813 -2.1049\n\n# Cluster around 10, with an SD of 4\nrnorm(5, mean = 10, sd = 4)\n\n[1]  3.529581  7.105072 11.226964 10.902385 13.742864\n\n## [1]  3.530  7.105 11.227 10.902 13.743\n\n\nset.seed(1234)\n\nplot_data &lt;- tibble(x = rnorm(1000, mean = 10, sd = 4))\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n       x\n   &lt;dbl&gt;\n1  5.17 \n2 11.1  \n3 14.3  \n4  0.617\n5 11.7  \n6 12.0  \n\n## # A tibble: 6 √ó 1\n##        x\n##    &lt;dbl&gt;\n## 1  5.17 \n## 2 11.1  \n## 3 14.3  \n## 4  0.617\n## 5 11.7  \n## 6 12.0\n\nggplot(plot_data, aes(x = x)) +\n  geom_histogram(binwidth = 1, boundary = 0, color = \"white\")\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nfake_people &lt;- tibble(income = rnorm(1000, mean = 40000, sd = 15000),\n                      age = rnorm(1000, mean = 25, sd = 8),\n                      education = rnorm(1000, mean = 16, sd = 4))\nhead(fake_people)\n\n# A tibble: 6 √ó 3\n  income   age education\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 21894. 15.4      12.1 \n2 44161. 27.4      15.6 \n3 56267. 12.7      15.6 \n4  4815. 30.1      20.8 \n5 46437. 30.6       9.38\n6 47591.  9.75     11.8 \n\n## # A tibble: 6 √ó 3\n##   income   age education\n##    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n## 1 21894. 15.4      12.1 \n## 2 44161. 27.4      15.6 \n## 3 56267. 12.7      15.6 \n## 4  4815. 30.1      20.8 \n## 5 46437. 30.6       9.38\n## 6 47591.  9.75     11.8\n\nfake_income &lt;- ggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated income\")\n\nfake_age &lt;- ggplot(fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated age\")\n\nfake_education &lt;- ggplot(fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated education\")\n\nfake_income + fake_age + fake_education\n\n\n\n\n\n\n\n\n\nChallenges of the Normal Distribution\nOne needs to plot these to get them looking correctly. Trial and error until the data looks reasonable. You may also wind up with negative numbers when that does not make any sense. You may need to do a truncated normal distribution check out this üì¶ https://github.com/olafmersmann/truncnorm This has a function that has arguments that sets an optional max and min value.\n\nset.seed(1234)\n\nplot_data &lt;- tibble(fake_age = rnorm(1000, mean = 14, sd = 5))\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n  fake_age\n     &lt;dbl&gt;\n1     7.96\n2    15.4 \n3    19.4 \n4     2.27\n5    16.1 \n6    16.5 \n\n## # A tibble: 6 √ó 1\n##   fake_age\n##      &lt;dbl&gt;\n## 1     7.96\n## 2    15.4 \n## 3    19.4 \n## 4     2.27\n## 5    16.1 \n## 6    16.5\n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nlibrary(truncnorm)  # For rtruncnorm()\n\nset.seed(1234)\n\nplot_data &lt;- tibble(fake_age = rtruncnorm(1000, mean = 14, sd = 5, a = 12, b = 21))\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n  fake_age\n     &lt;dbl&gt;\n1     15.4\n2     19.4\n3     16.1\n4     16.5\n5     14.3\n6     18.8\n\n## # A tibble: 6 √ó 1\n##   fake_age\n##      &lt;dbl&gt;\n## 1     15.4\n## 2     19.4\n## 3     16.1\n## 4     16.5\n## 5     14.3\n## 6     18.8\n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 0)"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#beta-distribution",
    "href": "posts/2023-11-04-synthetic-data/index.html#beta-distribution",
    "title": "Synthetic data",
    "section": "Beta Distribution",
    "text": "Beta Distribution\nI feel I need to understand this distribution but it is not quite sinking in.\nBeta distributions range from 0-1 and take the arguments of shape1 and shape2 and useful for percentages‚Äìthinking batting averages. This post is helpful. The formula is helpful‚Äìif I can display it correctly\n\\[\n\\frac{6}{6 + 4}\n\\]\n\nset.seed(1234)\n\nplot_data &lt;- tibble(exam_score = rbeta(1000, shape1 = 6, shape2 = 4)) %&gt;%\n  # rbeta() generates numbers between 0 and 1, so multiply everything by 10 to\n  # scale up the exam scores\n  mutate(exam_score = exam_score * 10)\n\nggplot(plot_data, aes(x = exam_score)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 0:10)\n\n\n\n\n\n\n\n\n\nPlotting Beta\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 6, shape2 = 4))\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 60, shape2 = 40))\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 9, shape2 = 1), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 1, shape2 = 9), color = \"red\")\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 5, shape2 = 5), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5), color = \"red\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 80, shape2 = 23), color = \"orange\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 13, shape2 = 17), color = \"brown\")\n\n\n\n\n\n\n\n\nOkay, I see it now‚Äì its the percentage not the total and that is what I am trying to figure it out. The distributions are split up almost in quarters and if you are interested in the red distribution one could fiddle with shape1 at 2 and shape 2 at 5. ##E\n\nset.seed(1234)\n\nplot_data &lt;- tibble(thing = rbeta(1000, shape1 = 2, shape2 = 5)) %&gt;%\n  mutate(thing = thing * 100)\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n  thing\n  &lt;dbl&gt;\n1 10.1 \n2 34.5 \n3 55.3 \n4  2.19\n5 38.0 \n6 39.9 \n\n## # A tibble: 6 √ó 1\n##   thing\n##   &lt;dbl&gt;\n## 1 10.1 \n## 2 34.5 \n## 3 55.3 \n## 4  2.19\n## 5 38.0 \n## 6 39.9\n\nggplot(plot_data, aes(x = thing)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#binomial-distributions",
    "href": "posts/2023-11-04-synthetic-data/index.html#binomial-distributions",
    "title": "Synthetic data",
    "section": "Binomial Distributions",
    "text": "Binomial Distributions\nFields that are binary; yes/no, treated/untreated.\n\nset.seed(1234)\n\n# Choose 5 random T/F values\npossible_things &lt;- c(TRUE, FALSE)\nsample(possible_things, 5, replace = TRUE)\n\n[1] FALSE FALSE FALSE FALSE  TRUE\n\n## [1] FALSE FALSE FALSE FALSE  TRUE\n\nBy default R will choose a uniform distribution. One can tinker with the probability\n\nset.seed(1234)\ncandidates &lt;- c(\"Person 1\", \"Person 2\")\nsample(candidates, size = 1, prob = c(0.8, 0.2))\n\n[1] \"Person 1\"\n\n## [1] \"Person 1\"\n\nWe may want to see all the possibilities.\n\n\n\nset.seed(1234)\nfake_elections &lt;- tibble(winner = sample(candidates,\n                                         size = 1000,\n                                         prob = c(0.8, 0.2),\n                                         replace = TRUE))\nfake_elections %&gt;%\n  count(winner)\n\n# A tibble: 2 √ó 2\n  winner       n\n  &lt;chr&gt;    &lt;int&gt;\n1 Person 1   792\n2 Person 2   208\n\n## # A tibble: 2 √ó 2\n##   winner       n\n##   &lt;chr&gt;    &lt;int&gt;\n## 1 Person 1   792\n## 2 Person 2   208\n\nggplot(fake_elections, aes(x = winner)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nThe rbinomhas two arguments;\n\nsize: the number of times a thing happens\nprob: the probability\n\n\nset.seed(1234)\n\nrbinom(5, size = 20, prob = 0.6)\n\n[1] 15 11 11 11 10\n\n## [1] 15 11 11 11 10\n\nA better way to do i\n\nset.seed(1234)\n\nrbinom(5, size = 1, prob = 0.6)\n\n[1] 1 0 0 0 0\n\n## [1] 1 0 0 0 0\n\n\nset.seed(12345)\n\nplot_data &lt;- tibble(thing = rbinom(2000, 1, prob = 0.6)) %&gt;%\n  # Make this a factor since it's basically a yes/no categorical variable\n  mutate(thing = factor(thing))\n\nplot_data %&gt;%\n  count(thing) %&gt;%\n  mutate(proportion = n / sum(n))\n\n# A tibble: 2 √ó 3\n  thing     n proportion\n  &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;\n1 0       840       0.42\n2 1      1160       0.58\n\n## # A tibble: 2 √ó 3\n##   thing     n proportion\n##   &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;\n## 1 0       840       0.42\n## 2 1      1160       0.58\n\nggplot(plot_data, aes(x = thing)) +\n  geom_bar()"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#poisson-distribution",
    "href": "posts/2023-11-04-synthetic-data/index.html#poisson-distribution",
    "title": "Synthetic data",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nIndependent random events that combine into grouped events. For example, traffic, number of people coming into a coffee shop; when they leave the coffee shop.\nThe function for this distribution is rpois and takes one argument:\n\nlambda rate or speed the process follows. How fast a process increases fro 1 to two.\n\n\nset.seed(123)\n\n# 10 different families\nrpois(10, lambda = 1)\n\n [1] 0 2 1 2 3 0 1 2 1 1\n\n##  [1] 0 2 1 2 3 0 1 2 1 1\n\n\nset.seed(1234)\n\nplot_data &lt;- tibble(num_kids = rpois(500, lambda = 1))\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n  num_kids\n     &lt;int&gt;\n1        0\n2        1\n3        1\n4        1\n5        2\n6        1\n\n## # A tibble: 6 √ó 1\n##   num_kids\n##      &lt;int&gt;\n## 1        0\n## 2        1\n## 3        1\n## 4        1\n## 5        2\n## 6        1\n\nplot_data %&gt;%\n  group_by(num_kids) %&gt;%\n  summarize(count = n()) %&gt;%\n  mutate(proportion = count / sum(count))\n\n# A tibble: 6 √ó 3\n  num_kids count proportion\n     &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n1        0   180      0.36 \n2        1   187      0.374\n3        2    87      0.174\n4        3    32      0.064\n5        4    11      0.022\n6        5     3      0.006\n\n## # A tibble: 6 √ó 3\n##   num_kids count proportion\n##      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n## 1        0   180      0.36 \n## 2        1   187      0.374\n## 3        2    87      0.174\n## 4        3    32      0.064\n## 5        4    11      0.022\n## 6        5     3      0.006\n\nggplot(plot_data, aes(x = num_kids)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNow we play with the lambda and see how the results change\n\nset.seed(1234)\n\nplot_data &lt;- tibble(num_kids = rpois(500, lambda = 2))\nhead(plot_data)\n\n# A tibble: 6 √ó 1\n  num_kids\n     &lt;int&gt;\n1        0\n2        2\n3        2\n4        2\n5        4\n6        2\n\n## # A tibble: 6 √ó 1\n##   num_kids\n##      &lt;int&gt;\n## 1        0\n## 2        2\n## 3        2\n## 4        2\n## 5        4\n## 6        2\n\nplot_data %&gt;%\n  group_by(num_kids) %&gt;%\n  summarize(count = n()) %&gt;%\n  mutate(proportion = count / sum(count))\n\n# A tibble: 8 √ó 3\n  num_kids count proportion\n     &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n1        0    62      0.124\n2        1   135      0.27 \n3        2   145      0.29 \n4        3    88      0.176\n5        4    38      0.076\n6        5    19      0.038\n7        6    10      0.02 \n8        7     3      0.006\n\n## # A tibble: 8 √ó 3\n##   num_kids count proportion\n##      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n## 1        0    62      0.124\n## 2        1   135      0.27 \n## 3        2   145      0.29 \n## 4        3    88      0.176\n## 5        4    38      0.076\n## 6        5    19      0.038\n## 7        6    10      0.02 \n## 8        7     3      0.006\n\nggplot(plot_data, aes(x = num_kids)) +\n  geom_bar()"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#rescaling-numbers",
    "href": "posts/2023-11-04-synthetic-data/index.html#rescaling-numbers",
    "title": "Synthetic data",
    "section": "Rescaling Numbers",
    "text": "Rescaling Numbers\nNot all distributions have a truncated version; the next section shows how to do this with the rescale function from the scales üì¶\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5))\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nfake_people &lt;- tibble(income = rbeta(1000, shape1 = 2, shape2 = 5))\n\nggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 0.1, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nfake_people_scaled &lt;- fake_people %&gt;%\n  mutate(income_scaled = rescale(income, to = c(10000, 100000)))\nhead(fake_people_scaled)\n\n# A tibble: 6 √ó 2\n  income income_scaled\n   &lt;dbl&gt;         &lt;dbl&gt;\n1 0.101         21154.\n2 0.345         49014.\n3 0.553         72757.\n4 0.0219        12176.\n5 0.380         53036.\n6 0.399         55162.\n\n## # A tibble: 6 √ó 2\n##   income income_scaled\n##    &lt;dbl&gt;         &lt;dbl&gt;\n## 1 0.101         21154.\n## 2 0.345         49014.\n## 3 0.553         72757.\n## 4 0.0219        12176.\n## 5 0.380         53036.\n## 6 0.399         55162.\n\nggplot(fake_people_scaled, aes(x = income_scaled)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nfake_data &lt;- tibble(age_not_scaled = rnorm(1000, mean = 0, sd = 1)) %&gt;%\n  mutate(age = rescale(age_not_scaled, to = c(18, 65)))\nhead(fake_data)\n\n# A tibble: 6 √ó 2\n  age_not_scaled   age\n           &lt;dbl&gt; &lt;dbl&gt;\n1         -1.21   33.6\n2          0.277  44.2\n3          1.08   49.9\n4         -2.35   25.5\n5          0.429  45.3\n6          0.506  45.8\n\n## # A tibble: 6 √ó 2\n##   age_not_scaled   age\n##            &lt;dbl&gt; &lt;dbl&gt;\n## 1         -1.21   33.6\n## 2          0.277  44.2\n## 3          1.08   49.9\n## 4         -2.35   25.5\n## 5          0.429  45.3\n## 6          0.506  45.8\n\nplot_unscaled &lt;- ggplot(fake_data, aes(x = age_not_scaled)) +\n  geom_histogram(binwidth = 0.5, color = \"white\", boundary = 0)\n\nplot_scaled &lt;- ggplot(fake_data, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0)\n\nplot_unscaled + plot_scaled"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#making-your-own-world",
    "href": "posts/2023-11-04-synthetic-data/index.html#making-your-own-world",
    "title": "Synthetic data",
    "section": "Making your own world",
    "text": "Making your own world\nThe code below provides examples of creating fake data sets; these don‚Äôt\n\nset.seed(1234)\n\n# Set the number of people here once so it's easier to change later\nn_people &lt;- 1000\n\nexample_fake_people &lt;- tibble(\n  id = 1:n_people,\n  opinion = sample(1:5, n_people, replace = TRUE),\n  age = runif(n_people, min = 18, max = 80),\n  income = rnorm(n_people, mean = 50000, sd = 10000),\n  education = rtruncnorm(n_people, mean = 16, sd = 6, a = 8, b = 24),\n  happiness = rbeta(n_people, shape1 = 2, shape2 = 1),\n  treatment = sample(c(TRUE, FALSE), n_people, replace = TRUE, prob = c(0.3, 0.7)),\n  size = rbinom(n_people, size = 1, prob = 0.5),\n  family_size = rpois(n_people, lambda = 1) + 1  # Add one so there are no 0s\n) %&gt;%\n  # Adjust some of these columns\n  mutate(opinion = recode(opinion, \"1\" = \"Strongly disagree\",\n                          \"2\" = \"Disagree\", \"3\" = \"Neutral\",\n                          \"4\" = \"Agree\", \"5\" = \"Strongly agree\")) %&gt;%\n  mutate(size = recode(size, \"0\" = \"Small\", \"1\" = \"Large\")) %&gt;%\n  mutate(happiness = rescale(happiness, to = c(1, 8)))\n\nhead(example_fake_people)\n\n# A tibble: 6 √ó 9\n     id opinion       age income education happiness treatment size  family_size\n  &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1     1 Agree        31.7 43900.      18.3      7.20 TRUE      Large           1\n2     2 Disagree     52.9 34696.      17.1      4.73 TRUE      Large           2\n3     3 Strongly a‚Ä¶  45.3 43263.      17.1      7.32 FALSE     Large           4\n4     4 Agree        34.9 40558.      11.7      4.18 FALSE     Small           2\n5     5 Strongly d‚Ä¶  50.3 41392.      13.3      2.61 TRUE      Small           2\n6     6 Strongly a‚Ä¶  63.6 69917.      11.2      4.36 FALSE     Small           2\n\n## # A tibble: 6 √ó 9\n##      id opinion             age income education happiness treatment size  family_size\n##   &lt;int&gt; &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;     &lt;chr&gt;       &lt;dbl&gt;\n## 1     1 Agree              31.7 43900.      18.3      7.20 TRUE      Large           1\n## 2     2 Disagree           52.9 34696.      17.1      4.73 TRUE      Large           2\n## 3     3 Strongly agree     45.3 43263.      17.1      7.32 FALSE     Large           4\n## 4     4 Agree              34.9 40558.      11.7      4.18 FALSE     Small           2\n## 5     5 Strongly disagree  50.3 41392.      13.3      2.61 TRUE      Small           2\n## 6     6 Strongly agree     63.6 69917.      11.2      4.36 FALSE     Small           2\n\n\nplot_opinion &lt;- ggplot(example_fake_people, aes(x = opinion)) +\n  geom_bar() +\n  guides(fill = \"none\") +\n  labs(title = \"Opinion (uniform with sample())\")\n\nplot_age &lt;- ggplot(example_fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0) +\n  labs(title = \"Age (uniform with runif())\")\n\nplot_income &lt;- ggplot(example_fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Income (normal)\")\n\nplot_education &lt;- ggplot(example_fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Education (truncated normal)\")\n\nplot_happiness &lt;- ggplot(example_fake_people, aes(x = happiness)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:8) +\n  labs(title = \"Happiness (Beta, rescaled to 1-8)\")\n\nplot_treatment &lt;- ggplot(example_fake_people, aes(x = treatment)) +\n  geom_bar() +\n  labs(title = \"Treatment (binary with sample())\")\n\nplot_size &lt;- ggplot(example_fake_people, aes(x = size)) +\n  geom_bar() +\n  labs(title = \"Size (binary with rbinom())\")\n\nplot_family &lt;- ggplot(example_fake_people, aes(x = family_size)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 1:7) +\n  labs(title = \"Family size (Poisson)\")\n\n(plot_opinion + plot_age) / (plot_income + plot_education)\n\n\n\n\n\n\n\n\n\n(plot_happiness + plot_treatment) / (plot_size + plot_family)"
  },
  {
    "objectID": "posts/2023-11-04-synthetic-data/index.html#finish",
    "href": "posts/2023-11-04-synthetic-data/index.html#finish",
    "title": "Synthetic data",
    "section": "Finish",
    "text": "Finish\nFor my purposes, I want to simulate something to the opinion. However, my data reference is not uniform so I could put in my mean and sd and to get an accurate simulation."
  },
  {
    "objectID": "posts/2022-11-10-make-terrible-gadgets/index.html",
    "href": "posts/2022-11-10-make-terrible-gadgets/index.html",
    "title": "Make terrible gadgets",
    "section": "",
    "text": "To make a good gadgets, you have to make some terrible ones. Actually the one I just made seems to have worked very well. Other than I need to load my own package, Shiny and MiniUI--but I think that is fixable."
  },
  {
    "objectID": "posts/2023-05-05-chat-gpt/index.html",
    "href": "posts/2023-05-05-chat-gpt/index.html",
    "title": "Chat GPT",
    "section": "",
    "text": "I disdain writing html tables and dislike trying to find example to copy and paste.\n\nPlease create an html table 3 columns and 5 rows\n\n\nAre you able to provide some basic styling to the table\n\n\n\n\nThis Table/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;table&gt;\n&lt;tr&gt;\n&lt;th&gt;\nColumn 1\n&lt;/th&gt;\n&lt;th&gt;\nColumn 2\n&lt;/th&gt;\n&lt;th&gt;\nColumn 3\n&lt;/th&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\nRow 1, Column 1\n&lt;/td&gt;\n&lt;td&gt;\nRow 1, Column 2\n&lt;/td&gt;\n&lt;td&gt;\nRow 1, Column 3\n&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\nRow 2, Column 1\n&lt;/td&gt;\n&lt;td&gt;\nRow 2, Column 2\n&lt;/td&gt;\n&lt;td&gt;\nRow 2, Column 3\n&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\nRow 3, Column 1\n&lt;/td&gt;\n&lt;td&gt;\nRow 3, Column 2\n&lt;/td&gt;\n&lt;td&gt;\nRow 3, Column 3\n&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\nRow 4, Column 1\n&lt;/td&gt;\n&lt;td&gt;\nRow 4, Column 2\n&lt;/td&gt;\n&lt;td&gt;\nRow 4, Column 3\n&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\nRow 5, Column 1\n&lt;/td&gt;\n&lt;td&gt;\nRow 5, Column 2\n&lt;/td&gt;\n&lt;td&gt;\nRow 5, Column 3\n&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;\nMy Table\n\n\n\n\n\n\n\nColumn 1\n\n\nColumn 2\n\n\nColumn 3\n\n\n\n\nRow 1, Column 1\n\n\nRow 1, Column 2\n\n\nRow 1, Column 3\n\n\n\n\nRow 2, Column 1\n\n\nRow 2, Column 2\n\n\nRow 2, Column 3\n\n\n\n\nRow 3, Column 1\n\n\nRow 3, Column 2\n\n\nRow 3, Column 3\n\n\n\n\nRow 4, Column 1\n\n\nRow 4, Column 2\n\n\nRow 4, Column 3\n\n\n\n\nRow 5, Column 1\n\n\nRow 5, Column 2\n\n\nRow 5, Column 3"
  },
  {
    "objectID": "posts/2024-05-27-markdown-code-to-r-script/index.html",
    "href": "posts/2024-05-27-markdown-code-to-r-script/index.html",
    "title": "Markdown Code to R script",
    "section": "",
    "text": "This worked\nI needed to grab the code out of a markdown document and I had a sense that there was function for this. However, there is a function to take to convert an R script to an Rmarkdown document. It is the spin function. Here was my introduction to the function.\nI am not sure if there is function to do the reverse.\nAnyway Chat-GPT created a script for me to use and it worked perfect. Here is the script link to the chat"
  },
  {
    "objectID": "posts/r-packages/r-packages.html",
    "href": "posts/r-packages/r-packages.html",
    "title": "R-packages",
    "section": "",
    "text": "QualtRics\nThe QualtRics pakcage is a key r package I utilize. The package provides an API access from Qualtrics to a R environment. If you manage separate Qualtrics accounts, set your credentials to project environmental settings. See below\n\n usethis::edit_r_environ(\"project\")"
  },
  {
    "objectID": "posts/2021-12-27-automated-testing-links/index.html",
    "href": "posts/2021-12-27-automated-testing-links/index.html",
    "title": "Automated Testing Links",
    "section": "",
    "text": "I stumbled upon these resources over the weekend and they gave me some ideas on how to automate some tests.\nI have been looking for this article; the article covers automated testing and deploying a Shiny Application. I suspect one could write the manifest to send to shinyapps.io.\nI liked the tips and tricks of this post"
  },
  {
    "objectID": "posts/2023-01-02-today-i-learned/index.html",
    "href": "posts/2023-01-02-today-i-learned/index.html",
    "title": "Today I learned",
    "section": "",
    "text": "I was making more difficult. I need to extract the month from dates submitted.\ntest_date &lt;- session_summary %&gt;% \n  dplyr::mutate(date = as.Date(date)) %&gt;% \n  dplyr::mutate(date = lubridate::ymd(date)) %&gt;% \n  dplyr::mutate(month = lubridate:: month(date, label = TRUE))\nThe worst is when the code runs and appears correct but is not.\nTurns out I was making the process too difficult here is the code chunk that worked.\nplay_session &lt;- session_summary %&gt;% \n  dplyr::mutate(new_date = lubridate::mdy(date)) %&gt;%\n  dplyr::mutate(month = lubridate:: month(new_date, label = TRUE))\nMaybe not optimized but it worked.\nUntil next time, cheers!"
  },
  {
    "objectID": "posts/2023-01-02-today-i-learned/index.html#dates-are-hard",
    "href": "posts/2023-01-02-today-i-learned/index.html#dates-are-hard",
    "title": "Today I learned",
    "section": "",
    "text": "I was making more difficult. I need to extract the month from dates submitted.\ntest_date &lt;- session_summary %&gt;% \n  dplyr::mutate(date = as.Date(date)) %&gt;% \n  dplyr::mutate(date = lubridate::ymd(date)) %&gt;% \n  dplyr::mutate(month = lubridate:: month(date, label = TRUE))\nThe worst is when the code runs and appears correct but is not.\nTurns out I was making the process too difficult here is the code chunk that worked.\nplay_session &lt;- session_summary %&gt;% \n  dplyr::mutate(new_date = lubridate::mdy(date)) %&gt;%\n  dplyr::mutate(month = lubridate:: month(new_date, label = TRUE))\nMaybe not optimized but it worked.\nUntil next time, cheers!"
  },
  {
    "objectID": "posts/2021-07-23-where-are-my-keys/index.html",
    "href": "posts/2021-07-23-where-are-my-keys/index.html",
    "title": "Where are my keys",
    "section": "",
    "text": "Today, I had to relearn how to reset a git remote.\n\nHappy Git with R.\nGreat Link\n\nThe problem:\nGithub was asking me a password when I have keys set up.\nStep 1:\nIn the terminal\ngit remote -v \nOkay the terminal is telling me that the remote is set to https:\nhttps://github.com/USERNAME/REPOSITORY.git\n\nThe fix\ngit remote set-url origin git@github.com:USERNAME/REPOSITORY.git\n\n\nFinish\nMy issue is that I was forgetting to include the origin."
  },
  {
    "objectID": "posts/2019-03-27-Pets/index.html",
    "href": "posts/2019-03-27-Pets/index.html",
    "title": "Pets",
    "section": "",
    "text": "Introduction\nThe TidyTuesday project for March 27, 2019 consisted of Pet Registrations from Seattle. I had the good fortune to work with this data set prior on a Chromebook Data Science data visualization project.\n\nLoad Libraries\n\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.0.9\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n\nRead in the data\n\nseattle_pets &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv\")\n\nRows: 52519 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (7): license_issue_date, license_number, animals_name, species, primary_...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nExplore the Data\n\ndplyr::glimpse(seattle_pets)\n\nRows: 52,519\nColumns: 7\n$ license_issue_date &lt;chr&gt; \"November 16 2018\", \"November 11 2018\", \"November 2‚Ä¶\n$ license_number     &lt;chr&gt; \"8002756\", \"S124529\", \"903793\", \"824666\", \"S119138\"‚Ä¶\n$ animals_name       &lt;chr&gt; \"Wall-E\", \"Andre\", \"Mac\", \"Melb\", \"Gingersnap\", \"Co‚Ä¶\n$ species            &lt;chr&gt; \"Dog\", \"Dog\", \"Dog\", \"Cat\", \"Cat\", \"Dog\", \"Dog\", \"C‚Ä¶\n$ primary_breed      &lt;chr&gt; \"Mixed Breed, Medium (up to 44 lbs fully grown)\", \"‚Ä¶\n$ secondary_breed    &lt;chr&gt; \"Mix\", \"Dachshund, Standard Wire Haired\", NA, NA, \"‚Ä¶\n$ zip_code           &lt;chr&gt; \"98108\", \"98117\", \"98136\", \"98117\", \"98144\", \"98103‚Ä¶\n\n\n\n\nExploratory Graphs\nFrom this graph we learn that there are many more dogs registered than cats.\n\nseattle_pets %&gt;%\n  ggplot(aes(x = species)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThis line chart proivdes the framework for a polished graph below. The code chunk below uses a one two punch with with lubridate and zoo to work with the dates.\n\n## add date and ym columns\nseattle_pets$date &lt;- lubridate::mdy(seattle_pets$license_issue_date)\nseattle_pets$ym &lt;- zoo::as.yearmon(seattle_pets$date, \"%y%m\")\n\n## how the number of licenses recorded has changed over time\nseattle_pets %&gt;%\n  ## group by yearmonth (`ym`)\n  group_by(ym) %&gt;% \n  ## count number within each group\n  summarise(n=n()) %&gt;%\n  ggplot(., aes(ym, n)) + \n  ## geom name for line chart\n  geom_line() +\n  scale_x_yearmon() + \n  xlab(\"\") + \n  ylab(\"Number of licenses\")\n\n\n\n\n\n\n\n\n\n\nExplanatory Graph\nThe data spans many years when there were no registrations or licences; I was able to use the filter function to emphasis that registrations were very limited prior to January 2017. In January 2017 you are able to observe the number of registrations increase from January 2017 and peaking in February 2018.\n\n## add date and ym columns\nseattle_pets$date &lt;- lubridate::mdy(seattle_pets$license_issue_date)\nseattle_pets$ym &lt;- zoo::as.yearmon(seattle_pets$date, \"%y%m\")\n\n## how the number of licenses recorded has changed over time\nseattle_pets %&gt;%\n  ## group by yearmonth (`ym`)\n  filter(ym &gt; \"June 2015\") %&gt;%\n  group_by(ym) %&gt;% \n  ## count number within each group\n  count(species) %&gt;%\n  ggplot(., aes(ym, n, group = species, color = species)) + \n  ## geom name for line chart\n  geom_line() +\n  scale_x_yearmon() + \n  xlab(\"\") +\n  ylab(\"Number of licenses\") +\n  scale_colour_manual(values = c(\"blue\",\"red3\",\"white\", \"grey\")) +\n  theme_fivethirtyeight() +\n  labs(title = \"Change in Licenses Over Time\") +\n  labs(caption = \"Seattle Open Data Portal\") \n\n\n\n\n\n\n\n\n\n\nExplanatory Bar Charts\nThe mutate statement here along with the reorder statement puts the bar graph in order. I saw another example where you can use reorder within the aes statement in ggplot2.\n\ncat_p &lt;- seattle_pets %&gt;%\n  filter(species == \"Cat\", animals_name != \"\") %&gt;%\n  group_by(animals_name) %&gt;% \n  summarise(n = n()) %&gt;% \n  filter(n &gt;49) %&gt;%\n  mutate(animals_name = reorder(animals_name, n)) %&gt;%\n  ggplot(aes(x = animals_name, y =n)) + \n  geom_bar(stat=\"identity\") +\n  coord_flip() +\n  theme_fivethirtyeight() +\n   theme         (axis.text = element_text(size = 14), \n                title = element_text(size = 16), \n                legend.position=\"none\", \n                plot.caption=element_text(size = 12), \n                panel.grid.major = element_blank(), \n                panel.grid.minor = element_blank(),\n                axis.text.x = element_blank() ) +\n \n  labs(title = \"Top Registered Cat Names in Seattle\") +\n  labs(subtitle = \"Cat Names with at least 50 observations\") +\n  labs(caption = \"Seattle's Open Data Portal\") +\n  ylab(\"Name Count\") +\n  xlab(\"Cat Name\")+\n  geom_text(aes(label = paste0(as.integer(n)),\n                x = animals_name,\n                y = n, \n            stat= \"identity\", \n            hjust = -0.2, \n            \n  \n            ))\n\nWarning: Ignoring unknown aesthetics: stat\n\ncat_p\n\n\n\n\n\n\n\n\n\ndog_p &lt;- seattle_pets %&gt;%\n  filter(species == \"Dog\", animals_name != \"\") %&gt;%\n  group_by(animals_name) %&gt;% \n  summarise(n = n()) %&gt;% \n  filter(n &gt;149) %&gt;%\n  mutate(animals_name = reorder(animals_name, n)) %&gt;%\n  ggplot(aes(x = animals_name, y =n)) + \n  geom_bar(stat=\"identity\") +\n  coord_flip() +\n  theme_fivethirtyeight() +\n  theme         (axis.text = element_text(size = 14), \n                title = element_text(size = 16), \n                legend.position=\"none\", \n                plot.caption=element_text(size = 12), \n                panel.grid.major = element_blank(), \n                panel.grid.minor = element_blank(),\n                axis.text.x = element_blank() ) +\n  labs(title = \"Top Registered Dog Names in Seattle\") +\n  labs(subtitle = \"Dog Names with at least 150 observations\") +\n  labs(caption = \"Seattle's Open Data Portal\") +\n  ylab(\"Name Count\") +\n  xlab(\"Dog Name\")+\n  geom_text(aes(label = paste0(as.integer(n)),\n                x = animals_name,\n                y = n, \n            stat= \"identity\", \n            hjust = -0.2, \n            ))\n\nWarning: Ignoring unknown aesthetics: stat\n\ndog_p\n\n\n\n\n\n\n\n\n\n\n\nConclusion\nI played with the five_thirtyeight theme and it worked well. I think it would work better with some colors in the bar plot but I am not sure how I would want to color this graph."
  },
  {
    "objectID": "posts/2021-11-15-testing-shiny-applications/index.html",
    "href": "posts/2021-11-15-testing-shiny-applications/index.html",
    "title": "Testing Shiny Applications",
    "section": "",
    "text": "At some point last year, I jumped into unit testing with the help of the pointblank package. Since then, I have improved my ability to work with the testthat package.\nHowever, I could not get a good grasp of unit tests for a shiny application. I was reading the Mastering Shiny Book and still could not grasp it. I did find this article that got me going. The exercise of running the script below and playing with the application and tests helped me understand the testing process for Shiny Applications.\nshinyAppTemplate(\"myapp\")\nI was able to implement a couple of simple automated tests in my own shiny applications. The only roadblock I ran into is that I had not exported my modules and the testing engine could not find the server I was testing.\nI start with simple tests and work towards more complexity. My favorite basic tests is to count the number of columns. Here is the form:\ntestServer(mod_home_server, {\n\nexpect_equal(ncol(sites()), 4)\n\n})\n\ntestServer(mod_home_server, {\n\nexpect_equal(colnames(program()), c(\"time\", \"site\", \"grant\", \"id_code\"))\n\n})"
  },
  {
    "objectID": "posts/2021-10-22-data-management/index.html",
    "href": "posts/2021-10-22-data-management/index.html",
    "title": "Data Management",
    "section": "",
    "text": "I discovered two great resources for data management in the past couple of weeks: Data Cleaning Plan and Data Audits\nWhat I like about both articles is that they are both:\n\nPractical\nApproachable for non-technical users. I feel I could share these articles and managers of social service providers could understand them.\n\nI started writing a data cleaning plan, and I am pleased I started the process. Writing out the plan provided a sense of relief to have it out of my head and into documentation. It also struck me that much of my data cleaning should be in my Readme file."
  },
  {
    "objectID": "posts/2023-09-10-population-pyramids/index.html",
    "href": "posts/2023-09-10-population-pyramids/index.html",
    "title": "Population Pyramids",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidycensus)\nlibrary(plotly)\n\nI am working through creating Population Pyramids using the tidycensus package. Also here is another tutorial on Pyramid Plots.\nThe graph below is copy of the example from the article; the only change is I changed to Polk County Florida, and will add some code comments to help me understand how the code works.\n\npolk &lt;- get_estimates(geography = \"county\", \n                             product = \"characteristics\", \n                             breakdown = c(\"SEX\", \"AGEGROUP\", \"HISP\"),  \n                             breakdown_labels = TRUE, \n                             state = \"FL\", \n                             county = \"Polk\")\n\nReview the data structure.\n\ndplyr::glimpse (polk)\n\nRows: 114\nColumns: 7\n$ GEOID    &lt;chr&gt; \"12105\", \"12105\", \"12105\", \"12105\", \"12105\", \"12105\", \"12105\"‚Ä¶\n$ NAME     &lt;chr&gt; \"Polk County, Florida\", \"Polk County, Florida\", \"Polk County,‚Ä¶\n$ year     &lt;int&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2‚Ä¶\n$ SEX      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male‚Ä¶\n$ AGEGROUP &lt;fct&gt; All ages, All ages, All ages, Age 0 to 4 years, Age 0 to 4 ye‚Ä¶\n$ HISP     &lt;chr&gt; \"Both Hispanic Origins\", \"Non-Hispanic\", \"Hispanic\", \"Both Hi‚Ä¶\n$ value    &lt;dbl&gt; 389036, 273105, 115931, 22146, 13638, 8508, 24387, 15188, 919‚Ä¶\n\nhead(polk)\n\n# A tibble: 6 √ó 7\n  GEOID NAME                  year SEX   AGEGROUP         HISP             value\n  &lt;chr&gt; &lt;chr&gt;                &lt;int&gt; &lt;chr&gt; &lt;fct&gt;            &lt;chr&gt;            &lt;dbl&gt;\n1 12105 Polk County, Florida  2022 Male  All ages         Both Hispanic ‚Ä¶ 389036\n2 12105 Polk County, Florida  2022 Male  All ages         Non-Hispanic    273105\n3 12105 Polk County, Florida  2022 Male  All ages         Hispanic        115931\n4 12105 Polk County, Florida  2022 Male  Age 0 to 4 years Both Hispanic ‚Ä¶  22146\n5 12105 Polk County, Florida  2022 Male  Age 0 to 4 years Non-Hispanic     13638\n6 12105 Polk County, Florida  2022 Male  Age 0 to 4 years Hispanic          8508\n\n\n\ncompare &lt;- filter(polk, str_detect(AGEGROUP, \"^Age\"), #exclude all ages\n                  HISP != \"Both Hispanic Origins\", #this helps us segement by eth rather than totals\n                  SEX != \"Both sexes\") %&gt;% #again we want to segement by eth and sex. \n  mutate(value = ifelse(SEX == \"Male\", -value, value)) #I think this used for plotting and using the abolute value for the pyramid plot. \n\nggplot(compare, aes(x = AGEGROUP, y = value, fill = SEX)) + \n  geom_bar(stat = \"identity\", width = 1) + \n  theme_minimal(base_family = \"Roboto\") + \n  scale_y_continuous(labels = function(y) paste0(abs(y / 1000), \"k\")) +  #I have no idea what abs is. Is is abreivation or aboslute value. \n  scale_x_discrete(labels = function(x) gsub(\"Age | years\", \"\", x)) + \n  scale_fill_manual(values = c(\"darkred\", \"navy\")) + \n  coord_flip() + \n  facet_wrap(~HISP) + \n  labs(x = \"\", \n       y = \"2022 Census Bureau population estimate\", \n       title = \"Population structure by Hispanic origin\", \n       subtitle = \"Polk County, Florida\", \n       fill = \"\", \n       caption = \"Data source: US Census Bureau population estimates & tidycensus R package\")\n\n\n\n\n\n\n\n\nHere is how Chat GPT3 Answered my questions.\nLets riff on this and get a Population Pyramid based on just SEX.\n\nnon_eth &lt;- filter(polk, str_detect(AGEGROUP, \"^Age\"), #exclude all ages\n                  HISP == \"Both Hispanic Origins\", #this helps us segement by eth rather than totals\n                  SEX != \"Both sexes\") %&gt;% #again we want to segement by eth and sex. \n  mutate(value = ifelse(SEX == \"Male\", -value, value)) #I think this used for plotting and using the abolute value for t\n\nAgain, review the data and its structure.\n\ndplyr::glimpse (non_eth)\n\nRows: 36\nColumns: 7\n$ GEOID    &lt;chr&gt; \"12105\", \"12105\", \"12105\", \"12105\", \"12105\", \"12105\", \"12105\"‚Ä¶\n$ NAME     &lt;chr&gt; \"Polk County, Florida\", \"Polk County, Florida\", \"Polk County,‚Ä¶\n$ year     &lt;int&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2‚Ä¶\n$ SEX      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male‚Ä¶\n$ AGEGROUP &lt;fct&gt; Age 0 to 4 years, Age 5 to 9 years, Age 10 to 14 years, Age 1‚Ä¶\n$ HISP     &lt;chr&gt; \"Both Hispanic Origins\", \"Both Hispanic Origins\", \"Both Hispa‚Ä¶\n$ value    &lt;dbl&gt; -22146, -24387, -25485, -25844, -25352, -24998, -27862, -2627‚Ä¶\n\nhead(non_eth)\n\n# A tibble: 6 √ó 7\n  GEOID NAME                  year SEX   AGEGROUP           HISP           value\n  &lt;chr&gt; &lt;chr&gt;                &lt;int&gt; &lt;chr&gt; &lt;fct&gt;              &lt;chr&gt;          &lt;dbl&gt;\n1 12105 Polk County, Florida  2022 Male  Age 0 to 4 years   Both Hispani‚Ä¶ -22146\n2 12105 Polk County, Florida  2022 Male  Age 5 to 9 years   Both Hispani‚Ä¶ -24387\n3 12105 Polk County, Florida  2022 Male  Age 10 to 14 years Both Hispani‚Ä¶ -25485\n4 12105 Polk County, Florida  2022 Male  Age 15 to 19 years Both Hispani‚Ä¶ -25844\n5 12105 Polk County, Florida  2022 Male  Age 20 to 24 years Both Hispani‚Ä¶ -25352\n6 12105 Polk County, Florida  2022 Male  Age 25 to 29 years Both Hispani‚Ä¶ -24998\n\n\n\npolk_sex &lt;- ggplot(non_eth, aes(x = AGEGROUP, y = value, fill = SEX)) + \n  geom_bar(stat = \"identity\", width = .85) + \n  theme_minimal(base_family = \"Roboto\") + \n  scale_y_continuous(labels = function(y) paste0(abs(y / 1000), \"k\")) +  #I have no idea what abs is. Is is abreivation or aboslute value. \n  scale_x_discrete(labels = function(x) gsub(\"Age | years\", \"\", x)) + \n  scale_fill_manual(values = c(\"darkred\", \"navy\")) + \n  coord_flip() + \n  labs(x = \"\", \n       y = \"2022 Census Bureau population estimate\", \n       title = \"Population structure by SEX\", \n       subtitle = \"Polk County, Florida\", \n       fill = \"\", \n       caption = \"Data source: US Census Bureau population estimates & tidycensus R package\")\n\npolk_sex\n\n\n\n\n\n\n\n\nI updated the width of the bars for this plot. I think it looks better and it helps me see the pattern.\nI think it may be helpful to make the plot interactive\n\ninteractive_plot &lt;- plotly::ggplotly(polk_sex)\n\ninteractive_plot"
  },
  {
    "objectID": "posts/2023-09-07-todos/index.html",
    "href": "posts/2023-09-07-todos/index.html",
    "title": "TODOs",
    "section": "",
    "text": "I discovered the¬†todotxt-mode¬†Visual Studio Code extension. This extension is the closest to¬†org-mode¬†I have found without having emacs.\nMy best TODO System was a text file; somehow, I moved away from it. This extension is critical to bringing me back to using text files."
  },
  {
    "objectID": "posts/2023-09-16-household-income-polk-county/index.html",
    "href": "posts/2023-09-16-household-income-polk-county/index.html",
    "title": "Household Income: Polk County",
    "section": "",
    "text": "I am working through the process working with Census Data using the tidycensus package. I have been copying and modifying the examples to get a sense for how I can use this data.\n\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(scales)\noptions(tigris_use_cache = TRUE)\n\npolk &lt;- get_acs(\n  state = \"FL\",\n  county = \"Polk\",\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  geometry = TRUE,\n  year = 2021\n)\n\nhead(polk)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -82.01433 ymin: 27.86185 xmax: -81.82854 ymax: 28.17202\nGeodetic CRS:  NAD83\n        GEOID                                      NAME   variable estimate\n1 12105015102 Census Tract 151.02, Polk County, Florida B19013_001    83750\n2 12105010402 Census Tract 104.02, Polk County, Florida B19013_001    50721\n3 12105010800    Census Tract 108, Polk County, Florida B19013_001    49265\n4 12105014905 Census Tract 149.05, Polk County, Florida B19013_001    62784\n5 12105011838 Census Tract 118.38, Polk County, Florida B19013_001    89300\n6 12105012303 Census Tract 123.03, Polk County, Florida B19013_001    65094\n    moe                       geometry\n1  6800 MULTIPOLYGON (((-81.84696 2...\n2  6762 MULTIPOLYGON (((-81.95061 2...\n3 18923 MULTIPOLYGON (((-81.97355 2...\n4  7841 MULTIPOLYGON (((-82.01411 2...\n5 16974 MULTIPOLYGON (((-81.92359 2...\n6 20419 MULTIPOLYGON (((-81.95816 2...\n\n\n\noptions(scipen = 999)\npolk_p &lt;- polk %&gt;%\n  ggplot(aes(fill = estimate)) + \n  geom_sf(color = NA)  +\n  scale_fill_viridis_c(option = \"magma\", labels = dollar_format()) +\n  labs(\n       title = \"Household Income: Estimates\", \n       subtitle = \"Polk County, Florida\", \n       caption = \"Data source: US Census Bureau population estimates & tidycensus R package\") +\n\n  theme_void()\n\npolk_p\n\n\n\n\n\n\n\n\nI needed help from ChatGPT to get the legend to dollars‚Äìhere is the link to the assistance log. Please note the variable names changed.\nLets make the plot interactive.\n\nplotly::ggplotly(polk_p)\n\n\n\n\n\n\nracevars &lt;- c(White = \"P2_005N\",   \n              Black = \"P2_006N\", \n              Asian = \"P2_008N\", \n              Hispanic = \"P2_002N\")\n\n### This is an interesting techinuqe pythonish \n\npolk_race &lt;- get_decennial(\n  geography = \"tract\",\n  variables = racevars,\n  state = \"FL\",\n  county = \"Polk County\",\n  geometry = TRUE,\n  summary_var = \"P2_001N\", #this is the total population in the census tract. \n  year = 2020,\n  sumfile = \"pl\"\n) \n\nGetting data from the 2020 decennial Census\n\n\nUsing the PL 94-171 Redistricting Data Summary File\n\n\nNote: 2020 decennial Census data use differential privacy, a technique that\nintroduces errors into data to preserve respondent confidentiality.\n‚Ñπ Small counts should be interpreted with caution.\n‚Ñπ See https://www.census.gov/library/fact-sheets/2021/protecting-the-confidentiality-of-the-2020-census-redistricting-data.html for additional guidance.\nThis message is displayed once per session.\n\nhead(polk_race)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -82.0564 ymin: 27.99637 xmax: -81.97668 ymax: 28.08173\nGeodetic CRS:  NAD83\n# A tibble: 6 √ó 6\n  GEOID       NAME        variable value summary_value                  geometry\n  &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;         &lt;dbl&gt;        &lt;MULTIPOLYGON [¬∞]&gt;\n1 12105012004 Census Tra‚Ä¶ White     1686          2556 (((-82.05595 28.03673, -‚Ä¶\n2 12105012004 Census Tra‚Ä¶ Black      147          2556 (((-82.05595 28.03673, -‚Ä¶\n3 12105012004 Census Tra‚Ä¶ Asian       42          2556 (((-82.05595 28.03673, -‚Ä¶\n4 12105012004 Census Tra‚Ä¶ Hispanic   555          2556 (((-82.05595 28.03673, -‚Ä¶\n5 12105012001 Census Tra‚Ä¶ White     2825          5798 (((-82.0564 28.08038, -8‚Ä¶\n6 12105012001 Census Tra‚Ä¶ Black     1460          5798 (((-82.0564 28.08038, -8‚Ä¶\n\n\n\npolk_race_p &lt;- polk_race %&gt;%\n  mutate(percent = 100 * (value / summary_value)) %&gt;%\n  ggplot(aes(fill = percent)) +\n  facet_wrap(~variable) +\n  geom_sf(color = NA) +\n  theme_void() + \n  scale_fill_viridis_c() + \n  labs(fill = \"% of population\\n(2020 Census)\",\n   title = \"Race Populatin Estimates\", \n       subtitle = \"Polk County, Florida\", \n       caption = \"Data source: US Census Bureau population estimates & tidycensus R package\") \n\n\nplotly::ggplotly(polk_race_p)\n\n\n\n\n\n\nConclusion\nWhat may useful is to also show the Census Tract for additional exploration."
  },
  {
    "objectID": "posts/2021-12-08-2021-12-eval-twitter-threads/index.html",
    "href": "posts/2021-12-08-2021-12-eval-twitter-threads/index.html",
    "title": "2021-12-Eval-Twitter-Threads",
    "section": "",
    "text": "2021-12-08\n\n\nFreelancers and consultants are not, unfortunately, mindreaders. We would like to craft very good proposals, and we need to understand the budget to do that.Please, please, #showthebudget in your evaluation RFPs.https://t.co/FKQtfbIZ0s pic.twitter.com/rYroCSkg8J\n\n‚Äî Three Hive Consulting (@Three_Hive) December 8, 2021\n\n\n\n\nExactly this. I‚Äôm always baffled by orgs who don‚Äôt include a budget, and then will tell you if you ask. Why not just include it? It‚Äôs also of course an #equity issue - who are the orgs/individuals who have time/capacity to write endless proposals? #eval #showthebudget https://t.co/k4Bh4SNwzV\n\n‚Äî Trilby Smith (@TrilbySmith) December 8, 2021\n\n\n\n\n2021-12-07\n\n\nDon‚Äôt begin any evaluation work without an official / formal contract from your client. (Repeat after me.)\n\n‚Äî Kavita Mittapalli, Ph.D.¬†(@KavitaMNA) December 7, 2021\n\n\n\n\nLet‚Äôs talk about contracts or the lack thereof. Here‚Äôs a short piece I just wrote/posted on my website and LinkedIn: https://t.co/70Z6MekAqD#contracts #evaluation #grants #smallbusiness #consultants\n\n‚Äî Kavita Mittapalli, Ph.D.¬†(@KavitaMNA) December 8, 2021"
  },
  {
    "objectID": "posts/2023-11-21-all-about-the-yaml/index.html",
    "href": "posts/2023-11-21-all-about-the-yaml/index.html",
    "title": "All about the YAML",
    "section": "",
    "text": "The Fun of YAML\n\nIf something‚Äôs wrong, just give me an error, YAML!\n\nYAML can be amusing ‚Äì and by that, I mean it‚Äôs genuinely frustrating. Unlike other languages, bad YAML doesn‚Äôt always result in an error; instead, it opts for a more passive-aggressive approach.\nHere are some sites that may help according to ChatGPT. Link to resources"
  },
  {
    "objectID": "posts/2024-07-25-fly-wheel/fly-wheel.html",
    "href": "posts/2024-07-25-fly-wheel/fly-wheel.html",
    "title": "Flywheels",
    "section": "",
    "text": "I liked this (Post). The insight is that we notice when someone is not very good or great at a skill. This may be overstated but there is some truth to it.\nThe same semantic applies when someone assumes someone was born to code or understands data.\n\nI can still feel the awkwardness of learning to code‚Äìit felt unnatural.\n\nWhat is great about learning to code/how computers work there is a the flywheel effect in that once you understand something many concepts fall into place."
  },
  {
    "objectID": "posts/2021-12-17-to-make-upper-case/index.html",
    "href": "posts/2021-12-17-to-make-upper-case/index.html",
    "title": "To make upper case",
    "section": "",
    "text": "I needed to make the values in a column consistent and was struggling to add in the base R function of toupper in a dplyr pipeline. I found the str_to_upper(string, locale = \"en\") function in the stringr package and made it work."
  },
  {
    "objectID": "posts/2024-03-17-hotel-internet/index.html",
    "href": "posts/2024-03-17-hotel-internet/index.html",
    "title": "Hotel Internet",
    "section": "",
    "text": "I attended the 2024 National Self-Direction Conference this week. I brought my Chromebook, and I struggled to get to the ‚ÄúCaptive Internet Portal.‚Äù\nQuick internet search (using mobile) help me uncover this page with some helpful hints\nBasically type in http://neverssl.com/ and that prompts that captive portal to open. I had to use this trick while at the Airport on the return flight home."
  },
  {
    "objectID": "posts/2024-09-22-links/index.html",
    "href": "posts/2024-09-22-links/index.html",
    "title": "Links",
    "section": "",
    "text": "I updated my R version to 4.4.1‚ÄìI suppressed the pain involved in updates such as re-installing packages. What has been fun is I don‚Äôt appear to be able to deploy my Shiny App to ShinyApps.io and it is not clear to me why.\n\n\nUseful R items:\nI have been waiting for this‚ÄìHow to secure static html files. This link https://nikitoshina.quarto.pub/quarto_encryption/ provides an example on how to do this. The tool to secure the file is JavaScript and it is required to have Node.js installed on your computer. This has the potential to be a game changer.\nUseful R üì¶ newpost; it uses the Rstudio API to create a new folder and starts a new post for you. This seems to work a bit better than my add-on.\nBrowser based Postgress database. I am not sure of my use case with this."
  },
  {
    "objectID": "posts/2024-09-22-links/index.html#items",
    "href": "posts/2024-09-22-links/index.html#items",
    "title": "Links",
    "section": "",
    "text": "Useful R items:\nI have been waiting for this‚ÄìHow to secure static html files. This link https://nikitoshina.quarto.pub/quarto_encryption/ provides an example on how to do this. The tool to secure the file is JavaScript and it is required to have Node.js installed on your computer. This has the potential to be a game changer.\nUseful R üì¶ newpost; it uses the Rstudio API to create a new folder and starts a new post for you. This seems to work a bit better than my add-on.\nBrowser based Postgress database. I am not sure of my use case with this."
  },
  {
    "objectID": "posts/2024-02-25-quality-control/index.html",
    "href": "posts/2024-02-25-quality-control/index.html",
    "title": "Quality Control",
    "section": "",
    "text": "I appreciate this blog post about quality control.\nAn important gist of the article is to not just have standards documented but to communicate and train on them.\nEvergreen finishes her blog post with this sentence:\n\nConsistent high-quality work is a result of quality control measures.\n\nMy takeaway quality control needs to be a system/process.\nWhile I personally utilize checklists, I am uncertain whether we are effectively communicating and training our subcontractors on these standards. The hope that this would create an effective feedback loop."
  },
  {
    "objectID": "posts/2023-05-08-impact-of-ai/index.html",
    "href": "posts/2023-05-08-impact-of-ai/index.html",
    "title": "Impact of AI",
    "section": "",
    "text": "Here is a link to an insightful podcast about the potentials and pitfalls of AI.\nA guest, Emily Bender a professor at the University of Washington points out that it is not really AI. Chat-GPT is language model that is really good at prediction of what comes next and summary. I believe she was making the argument that the OpenAI was engineering Chat-GPT to make it seem like the product has intelligence and giving it human like qualities."
  },
  {
    "objectID": "posts/2023-02-19-one-down/index.html",
    "href": "posts/2023-02-19-one-down/index.html",
    "title": "One down",
    "section": "",
    "text": "I finished the html portion of the Web Design course today. I spent about 2 hours over the last two days working on it. I want to be sure to reflect on what I learned from these courses and not just buzz through them.\nNews things I learned included the following html elements:\n\nfigure\nfigcaption\nfieldset\n\nAnchoring links and images is still a struggle and form elements is still a struggle. I look forward to the courses that focus on forms."
  },
  {
    "objectID": "posts/2021-12-20-back-to-gitlab/index.html",
    "href": "posts/2021-12-20-back-to-gitlab/index.html",
    "title": "Back to Gitlab",
    "section": "",
    "text": "Full stop, I prefer Gitlab!\n\nI started shifting to using Github mainly because of the usethis package\nI am thankful the folks at ThinkR have picked up the development of the gitlabr package. I really liked the ability to pull down and create issues directly from R."
  },
  {
    "objectID": "posts/sql/learn-sql.html",
    "href": "posts/sql/learn-sql.html",
    "title": "SQL Form",
    "section": "",
    "text": "ALTER TABLE &lt;table_name&gt; ADD COLUMN &lt;column_name&gt; &lt;DATA_TYPE&gt; &lt;CONSTRAINTS&gt;;"
  },
  {
    "objectID": "posts/sql/learn-sql.html#add-table",
    "href": "posts/sql/learn-sql.html#add-table",
    "title": "SQL Form",
    "section": "",
    "text": "ALTER TABLE &lt;table_name&gt; ADD COLUMN &lt;column_name&gt; &lt;DATA_TYPE&gt; &lt;CONSTRAINTS&gt;;"
  },
  {
    "objectID": "posts/sql/learn-sql.html#add-column-to-a-table",
    "href": "posts/sql/learn-sql.html#add-column-to-a-table",
    "title": "SQL Form",
    "section": "Add column to a table",
    "text": "Add column to a table\nALTER TABLE &lt;table_name&gt; ADD COLUMN &lt;column_name&gt; &lt;DATA_TYPE&gt; &lt;CONSTRAINTS&gt;;"
  },
  {
    "objectID": "posts/2022-11-10-playing/index.html",
    "href": "posts/2022-11-10-playing/index.html",
    "title": "playing",
    "section": "",
    "text": "This is a helpful post from Thomas Mock about how to write a function to automate blog post. Thus far, I have truly missed my blogdown addin.\nMaybe I should try to write my own addin. I manged to get an addin in place but does not work. I need to feed the function arguments."
  },
  {
    "objectID": "posts/2021-10-04-domain-expertise/index.html",
    "href": "posts/2021-10-04-domain-expertise/index.html",
    "title": "Domain Expertise",
    "section": "",
    "text": "Introduction\nIt is very cool when someone articulates a sense you have brewing beneath the surface.\n\n\nI‚Äôm on a tech centered biz team and we do lots of exploration using technical tools to figure out how to solve biz problems. Then pro devs turn our code into prod. Too few shops have tech centered biz folks then they wonder why wrong stuff gets built. ü§∑‚Äç‚ôÇÔ∏è https://t.co/WpclQkj1Ys\n\n‚Äî JD Long (@CMastication) October 3, 2021\n\n\nIn a less formal fashion, this is how my shop works‚Äìmy issue is that I am knee deep in the business process and doing the data exploration.\nThis is my process\n\nHey, I can query this‚Äìcan you make this pretty?\n\nA couple of days ago I replied with this tweet to a question.\n\n\nThis is where domain expertise ‚Äòshines‚Äô. I shine when I have a sense for what is important and what program staff need to do their jobs. I flail with layout and structure when I am not sure what is helpful.\n\n‚Äî Kevin Gilds (@Kevin_Gilds) September 30, 2021\n\n\n\n\nConclusion\nDifferent but closely related."
  },
  {
    "objectID": "posts/2021-12-22-command-line/index.html",
    "href": "posts/2021-12-22-command-line/index.html",
    "title": "Command Line",
    "section": "",
    "text": "Here is a fun video/content on using the command line. Command Line. Good stuff with ls command and navigation."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "R for Social Good",
    "section": "",
    "text": "Kevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nAll Equal()\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nCron-Jobs-GHA\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nStylying a Shiny App\n\n\n\n\n\n\n-Shiny -TIL\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nTest Your SQL\n\n\n\n\n\n\nSQL\n\n\n\n\n\n\n\n\n\nNov 4, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nGithub Actions\n\n\n\n\n\n\nGHA\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\n\nLinks\n\n\n\nResources\n\n\n\n\n\nSep 22, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nFlywheels\n\n\n\n\n\n\nskills\n\n\n\nMaking Skills look easy \n\n\n\n\n\nJul 25, 2024\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying with Mapboxer Pkg\n\n\n\n\n\n\nmaps\n\n\n\nPlaying with the Mapboxer Pkg \n\n\n\n\n\nJul 20, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nCL Shortcuts\n\n\n\n\n\n\nCL\n\n\n\nPlaying with the Command Line \n\n\n\n\n\nJul 7, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nVIM\n\n\n\n\n\n\nComputer Literacy\n\n\n\nPlaying with VIM \n\n\n\n\n\nJul 7, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nApologies\n\n\n\n\n\n\n-Life\n\n\n\nThinking about apologies \n\n\n\n\n\nJun 15, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown Code to R script\n\n\n\n\n\n\n-Chat-GPT\n\n\n\nUsed Chat GPT to help me with this \n\n\n\n\n\nMay 27, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nPlumber Fun\n\n\n\n\n\n\n-API, Plumber, Workflow\n\n\n\nTroubleshooting API End Points \n\n\n\n\n\nMay 18, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nPurpose of this data?\n\n\n\n\n\n\n-Data Management\n\n\n\nData Request Forms \n\n\n\n\n\nMar 30, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nHotel Internet\n\n\n\n\n\n\n-Hack\n\n\n\nWork around for captive web portals \n\n\n\n\n\nMar 17, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nCalendar & To Do List\n\n\n\n\n\n\n-Sanity\n\n\n\nA Blog Post Pairing Calendar & To Do List \n\n\n\n\n\nMar 2, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nQuality Control\n\n\n\n\n\n\n-Quality, Checklists\n\n\n\nPost about Quality Control \n\n\n\n\n\nFeb 25, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nMermaid Diagrams\n\n\n\n\n\n\n-Process Documentation\n\n\n\nPlaying with Mermaid Diagrams \n\n\n\n\n\nFeb 12, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nText Analysis\n\n\n\n\n\n\n-Text Analysis\n\n\n\n\n\n\n\n\n\nJan 7, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nWeather and RSS on the Command Line\n\n\n\n\n\n\n-CLI\n\n\n\nFun at the command line \n\n\n\n\n\nJan 7, 2024\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nTop_frac Inverse\n\n\n\n\n\n\n-Chat-GPT, DPLYR\n\n\n\nGetting to the bottom half \n\n\n\n\n\nDec 30, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nIs Not Null\n\n\n\n\n\n\n-SQL -MS Access\n\n\n\nIs Not Null Explanation \n\n\n\n\n\nDec 1, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nPivot Longer\n\n\n\n\n\n\n-dplyr, -ChatGPT, -Google Colab\n\n\n\nIterating Pivot Longer with ChatGPT \n\n\n\n\n\nNov 22, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nAll about the YAML\n\n\n\n\n\n\n-YAML\n\n\n\nQuartro Sites \n\n\n\n\n\nNov 21, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic data\n\n\n\n\n\n\n-Stats\n\n\n\nSimulation \n\n\n\n\n\nNov 4, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nHousehold Income: Polk County\n\n\n\n\n\n\nTidyCensus\n\n\n\nMap Polk County Household Income \n\n\n\n\n\nSep 16, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation Pyramids\n\n\n\n\n\n\n-Census, ACS pyramid-plots\n\n\n\nWorking with Tidy Census Data \n\n\n\n\n\nSep 10, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nTODOs\n\n\n\n\n\n\n-TODO\n\n\n\nDid I find it? \n\n\n\n\n\nSep 7, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nMore Google Colab\n\n\n\n\n\n\nGoogle Colab\n\n\n\nUsing R with Google Colab \n\n\n\n\n\nJul 20, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nStyle for Gmail\n\n\n\n\n\n\n-Google App Script -Chat GPT\n\n\n\nThe sage of styling an html table for Gmail \n\n\n\n\n\nJul 17, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nColab\n\n\n\n\n\n\n-Google Drive\n\n\n\nUse Python or R with Google Drive \n\n\n\n\n\nJul 4, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned\n\n\n\n\n\n\n-Google Sheets\n\n\n\nNo Query for you with xls \n\n\n\n\n\nJun 23, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nUNPIVOT\n\n\n\n\n\n\n-ChatGPT -GoogleSheets\n\n\n\nUNPIVOT IN GOOGLE SHEETS \n\n\n\n\n\nJun 22, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nWeb Stuff\n\n\n\n\n\n\n-Quartro\n\n\n\nAdding a footer to blog posts \n\n\n\n\n\nJun 3, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nBranches\n\n\n\n\n\n\n-Git -Shiny -Usethis\n\n\n\nWhy we branch \n\n\n\n\n\nMay 29, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nGlue\n\n\n\n\n\n\n-Glue\n\n\n\nGlue \n\n\n\n\n\nMay 29, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nMutating for Good\n\n\n\n\n\n\n-Google Sheets\n\n\n\nCreate Extra Data to make it work \n\n\n\n\n\nMay 29, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nSpreadsheet Data to Google Calendar\n\n\n\n\n\n\nGoogle App Script\n\n\n\nGoogle App Script to add Events from spreadsheet to Google Calandar \n\n\n\n\n\nMay 28, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nThe Img Tag\n\n\n\n\n\n\n-html -img -freecodecamp\n\n\n\nThe img tag \n\n\n\n\n\nMay 25, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\ni, Robot\n\n\n\n\n\n\nBooks\n\n\nChat GPT\n\n\n\nMore than Science Fiction \n\n\n\n\n\nMay 12, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of AI\n\n\n\n\n\n\nChat GPT\n\n\n\nGood reminders \n\n\n\n\n\nMay 8, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nChat GPT\n\n\n\n\n\n\nChat GPT\n\n\n\nHtml tables \n\n\n\n\n\nMay 5, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nData Dictionary\n\n\n\n\n\nArtilce on Pointblank Package \n\n\n\n\n\nApr 28, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Documents\n\n\n\n\n\nSketching out ideas \n\n\n\n\n\nApr 5, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nWhat to write\n\n\n\n\n\nGetting the grove back \n\n\n\n\n\nApr 3, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nEmail on edit\n\n\n\n\n\nThis video gave me an idea \n\n\n\n\n\nFeb 21, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nChecklists\n\n\n\n\n\nLove and Hate them \n\n\n\n\n\nFeb 20, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nOne down\n\n\n\n\n\nFinished the Learn HTML Section \n\n\n\n\n\nFeb 19, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\nInputs and Outpus \n\n\n\n\n\nFeb 18, 2023\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nR & Linux\n\n\n\n\n\nRember this post \n\n\n\n\n\nJan 15, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nWilcox-signed-rank-test\n\n\n\n\n\nA good article on this topic \n\n\n\n\n\nJan 10, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nThis week I learned\n\n\n\n\n\nPancakes \n\n\n\n\n\nJan 3, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned\n\n\n\n\n\nMaking dates more difficult \n\n\n\n\n\nJan 2, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nStreaks\n\n\n\n\n\nBegin again \n\n\n\n\n\nJan 1, 2023\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned\n\n\n\n\n\nA script to filter multiple values \n\n\n\n\n\nDec 29, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nData Types\n\n\n\n\n\nWhen something is not working as expected; check the data type \n\n\n\n\n\nDec 16, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nLazy & Automation\n\n\n\n\n\nThanksgiving weekend \n\n\n\n\n\nNov 26, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nApp Script\n\n\n\n\n\nGoogle Sheets \n\n\n\n\n\nNov 23, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nCodebooks and More\n\n\n\n\n\nCodebooks \n\n\n\n\n\nNov 16, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nLikert Scales\n\n\n\n\n\nThe saga \n\n\n\n\n\nNov 15, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nReprex\n\n\n\n\n\nReprex and other items I learned today \n\n\n\n\n\nNov 12, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nImport Packages\n\n\n\n\n\nBe nice \n\n\n\n\n\nNov 11, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nMake terrible gadgets\n\n\n\n\n\nTo make good gadgets you have to make some stinkers \n\n\n\n\n\nNov 10, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nplaying\n\n\n\n\n\nPlaying with addins \n\n\n\n\n\nNov 10, 2022\n\n\nKevin Gilds, MPA, Kevn Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nmove\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\njoins\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nR-packages\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\naddins\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nsql cert\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nbash\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nforeign keys\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Form\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\nKevin Gilds, MPA\n\n\n\n\n\n\n\n\n\n\n\n\nNano\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\n\n\nJan 9, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nGit Hooks\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 8, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\ncommit to the static\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 7, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nColumn Names\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 5, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nA README Tale\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 4, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\ndata-types\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 3, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nflextable\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 2, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nDocker Tutorial\n\n\n\n\n\n\nDocker\n\n\n\n\n\n\n\n\n\nJan 1, 2022\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nDocker\n\n\n\n\n\n\nDocker\n\n\n\n\n\n\n\n\n\nDec 30, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nSubmodules\n\n\n\n\n\n\nShiny\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 29, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nShiny Proxy Fun\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 28, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Testing Links\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 27, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nWriting in Community\n\n\n\n\n\n\nAkimbo\n\n\n\n\n\n\n\n\n\nDec 23, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nCommand Line\n\n\n\n\n\n\nLinux\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nMaps!\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 21, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nBack to Gitlab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nTIL\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 19, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nAbstraction\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 18, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nTo make upper case\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 17, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nFun with Readme & Github Actions\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 14, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nDashboards\n\n\n\n\n\n\nEvaluation\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 11, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nLinux-Twitter\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\n\n\nDec 8, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\n2021-12-Eval-Twitter-Threads\n\n\n\n\n\n\nEvaluation\n\n\n\n\n\n\n\n\n\nDec 8, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Shiny Applications\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 15, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nIssue-Templates\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 1, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nFile-Paths\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 30, 2021\n\n\nKevin Gilds, MPA, kevin\n\n\n\n\n\n\n\n\n\n\n\n\nData Management\n\n\n\n\n\n\nevaluation\n\n\n\n\n\n\n\n\n\nOct 24, 2021\n\n\nKevin Gilds, MPA, kevin\n\n\n\n\n\n\n\n\n\n\n\n\nDomain Expertise\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 4, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nCommunication Toolbox with Shiny\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nSep 24, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nShaking up Mental Models\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nSep 14, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nLessons\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nAug 31, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nWhere are my keys\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJul 23, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nSide Benefits of Learning R\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJun 16, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nAcross\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJun 13, 2021\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nPets\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nMar 27, 2019\n\n\nKevin Gilds, MPA, Kevin\n\n\n\n\n\n\n\n\n\n\n\n\nMaps\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 9, 2018\n\n\nKevin Gilds, MPA, kevin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-11-10-Cron-Jobs-GHA/2024-11-10-Cron-Jobs-GHA.html",
    "href": "posts/2024-11-10-Cron-Jobs-GHA/2024-11-10-Cron-Jobs-GHA.html",
    "title": "Cron-Jobs-GHA",
    "section": "",
    "text": "I scheduled my first GHA with a cron job. The idea was to set it for 5:00 am every Sunday.\nI was happy this morning that my GHA ran but was surprised that it ran early than expected. I realized that I need to factor in time zones and that my schedule was set for UTC. Claude A.I. was able to help me reset it for Eastern Standard time."
  },
  {
    "objectID": "posts/2024-11-11-All.Equal()/All.Equal().html",
    "href": "posts/2024-11-11-All.Equal()/All.Equal().html",
    "title": "All Equal()",
    "section": "",
    "text": "Today I need to find a difference between two data frames. Actually, I had to split the data frame and find the difference between two survey entries.\n\n## Create lists\ndf_list &lt;- split(dupes, dupes$response_id)\n\n\n### Split the list as save a data frame\ndf_1 &lt;- as.tibble(df_list[1])\n\ndf_2 &lt;- as.tibble(df_list[2])\n\n\nall.equal(df_1, df_2)\n\nCompares the date frame and I could easily tell there were many differences between these two entries. If I had time I would use fake data. Here is the üì¶documentation"
  }
]